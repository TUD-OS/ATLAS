diff --git a/cmdutils.c b/cmdutils.c
index 2c84394..6661266 100644
--- a/cmdutils.c
+++ b/cmdutils.c
@@ -19,6 +19,10 @@
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
  */
 
+/* disable warnings so they do not get in the way when compiling ffplay */
+#pragma GCC diagnostic ignored "-Wall"
+#pragma GCC diagnostic ignored "-Wpointer-sign"
+
 #include <string.h>
 #include <stdlib.h>
 #include <errno.h>
diff --git a/ffplay.c b/ffplay.c
index 779c879..38e4fbd 100644
--- a/ffplay.c
+++ b/ffplay.c
@@ -56,6 +56,19 @@
 
 #include "cmdutils.h"
 
+#include <pthread.h>
+#include "nalu.h"
+#include "jobs.h"
+
+#if defined(METRICS_NONE)
+# define METRICS_COUNT 0
+#elif defined(METRICS_REDUCED)
+# define METRICS_COUNT 5
+#else
+# define METRICS_FULL 1
+# define METRICS_COUNT 12
+#endif
+
 #include <unistd.h>
 #include <assert.h>
 
@@ -132,6 +145,7 @@ typedef struct VideoState {
     AVInputFormat *iformat;
     int no_background;
     int abort_request;
+    int abort_refresh;
     int force_refresh;
     int paused;
     int last_paused;
@@ -889,6 +903,8 @@ static void video_audio_display(VideoState *s)
     }
 }
 
+static int refresh_thread(void *);
+
 static void stream_close(VideoState *is)
 {
     VideoPicture *vp;
@@ -896,6 +912,8 @@ static void stream_close(VideoState *is)
     /* XXX: use a special url_shutdown call to abort parse cleanly */
     is->abort_request = 1;
     SDL_WaitThread(is->read_tid, NULL);
+    atlas_job_submit_relative(refresh_thread, 0.0, 0, NULL);  // one more iteration to notice abort
+    is->abort_refresh = 1;  // different abort variable so we cannot submit jobs to a terminated queue
     SDL_WaitThread(is->refresh_tid, NULL);
     packet_queue_destroy(&is->videoq);
     packet_queue_destroy(&is->audioq);
@@ -1003,17 +1021,49 @@ static void video_display(VideoState *is)
 static int refresh_thread(void *opaque)
 {
     VideoState *is= opaque;
-    while (!is->abort_request) {
+    int consume_next_frame = 1;
+    
+    atlas_job_queue_checkin(refresh_thread);
+    
+    while (!is->abort_refresh) {
+        if (consume_next_frame)
+            atlas_job_next(refresh_thread);
+        
+        /* match the conditions from video_refresh() here, so we know when the next frame will be consumed there */
+        consume_next_frame = 0;
+        
+        if (is->refresh)
+            goto throttle;
+        if (is->video_st) {
+            if (is->pictq_size == 0)
+                goto throttle;
+            if (is->paused)
+                goto refresh;
+            
+            double wait = (is->frame_timer + is->frame_last_duration) - av_gettime() / 1000000.0;
+            if (wait > 0)
+                usleep(wait * 1000000);
+            consume_next_frame = 1;
+        }
+        
+    refresh:;
         SDL_Event event;
         event.type = FF_REFRESH_EVENT;
         event.user.data1 = opaque;
-        if (!is->refresh && (!is->paused || is->force_refresh)) {
+        event.user.code = consume_next_frame;
+        assert(!is->refresh);
+        if (!is->paused || is->force_refresh) {
             is->refresh = 1;
             SDL_PushEvent(&event);
         }
+        if (consume_next_frame) continue;
+    throttle:
         //FIXME ideally we should wait the correct time but SDLs event passing is so slow it would be silly
         usleep(is->audio_st && is->show_mode != SHOW_MODE_VIDEO ? rdftspeed*1000 : 5000);
     }
+    
+    atlas_job_queue_terminate(refresh_thread);
+    
     return 0;
 }
 
@@ -1151,7 +1201,7 @@ static void video_refresh(void *opaque)
     SubPicture *sp, *sp2;
 
     if (is->video_st) {
-retry:
+        assert(is->pictq_size > 0);  // changes to the refresh_thread should ensure we always have a frame
         if (is->pictq_size == 0) {
             SDL_LockMutex(is->pictq_mutex);
             if (is->frame_last_dropped_pts != AV_NOPTS_VALUE && is->frame_last_dropped_pts > is->frame_last_pts) {
@@ -1167,7 +1217,7 @@ retry:
 
             if (vp->skip) {
                 pictq_next_picture(is);
-                goto retry;
+                return;  // only consume one frame at a time, or we will get out of sync with submitted jobs
             }
 
             if (is->paused)
@@ -1182,6 +1232,7 @@ retry:
             delay = compute_target_delay(is->frame_last_duration, is);
 
             time= av_gettime()/1000000.0;
+            assert(time >= is->frame_timer + delay);  // changes to the refresh_thread should ensure we never get here too early
             if (time < is->frame_timer + delay)
                 return;
 
@@ -1203,7 +1254,7 @@ retry:
                 if(is->pictq_size > 1){
                     is->frame_drops_late++;
                     pictq_next_picture(is);
-                    goto retry;
+                    return;  // only consume one frame at a time, or we will get out of sync with submitted jobs
                 }
             }
 
@@ -1477,6 +1528,10 @@ static int queue_picture(VideoState *is, AVFrame *src_frame, double pts1, int64_
         SDL_LockMutex(is->pictq_mutex);
         is->pictq_size++;
         SDL_UnlockMutex(is->pictq_mutex);
+        
+        double deadline = is->frame_timer + is->pictq_size * av_q2d(is->video_st->codec->time_base);
+        atlas_job_submit_absolute(refresh_thread, deadline, 0, NULL);
+        atlas_job_submit_absolute(video_refresh, deadline, 0, NULL);
     }
     return 0;
 }
@@ -1688,8 +1743,14 @@ static int input_request_frame(AVFilterLink *link)
     AVPacket pkt;
     int ret;
 
-    while (!(ret = get_video_frame(priv->is, priv->frame, &pts, &pkt)))
+    do {
+        ret = get_video_frame(priv->is, priv->frame, &pts, &pkt);
+    } while (pkt.data == flush_pkt.data);  // flush packets are not individual jobs, consume collaterally...
+    if (ret == 0) {
+        // ... decoding a packet without receiving a frame however is an individual job, so we must return this state
         av_free_packet(&pkt);
+        return AVERROR(EAGAIN);
+    }
     if (ret < 0)
         return -1;
 
@@ -1775,7 +1836,7 @@ static int configure_video_filters(AVFilterGraph *graph, VideoState *is, const c
 #if FF_API_OLD_VSINK_API
     ret = avfilter_graph_create_filter(&filt_out,
                                        avfilter_get_by_name("buffersink"),
-                                       "out", NULL, pix_fmts, graph);
+                                       "out", NULL, (void *)pix_fmts, graph);  // warning fix
 #else
     buffersink_params->pixel_fmts = pix_fmts;
     ret = avfilter_graph_create_filter(&filt_out,
@@ -1825,6 +1886,9 @@ static int configure_video_filters(AVFilterGraph *graph, VideoState *is, const c
 
 #endif  /* CONFIG_AVFILTER */
 
+static pthread_cond_t video_barrier;
+static pthread_mutex_t video_barrier_mutex = PTHREAD_MUTEX_INITIALIZER;
+
 static int video_thread(void *arg)
 {
     VideoState *is = arg;
@@ -1833,6 +1897,11 @@ static int video_thread(void *arg)
     double pts;
     int ret;
 
+    atlas_job_queue_checkin(video_thread);
+    pthread_mutex_lock(&video_barrier_mutex);
+    pthread_cond_signal(&video_barrier);
+    pthread_mutex_unlock(&video_barrier_mutex);
+
 #if CONFIG_AVFILTER
     AVFilterGraph *graph = avfilter_graph_alloc();
     AVFilterContext *filt_out = NULL;
@@ -1856,6 +1925,8 @@ static int video_thread(void *arg)
         AVFilterBufferRef *picref;
         AVRational tb = filt_out->inputs[0]->time_base;
 #endif
+        atlas_job_next(video_thread);
+
         while (is->paused && !is->videoq.abort_request)
             SDL_Delay(10);
 #if CONFIG_AVFILTER
@@ -1872,6 +1943,8 @@ static int video_thread(void *arg)
             last_h = is->video_st->codec->height;
         }
         ret = av_buffersink_get_buffer_ref(filt_out, &picref, 0);
+        if (ret == AVERROR(EAGAIN))
+            continue;  // we decoded a packet resulting in no frame; start next job
         if (picref) {
             avfilter_fill_frame_from_video_buffer_ref(frame, picref);
             pts_int = picref->pts;
@@ -1901,6 +1974,9 @@ static int video_thread(void *arg)
         if (ret < 0)
             goto the_end;
 
+        // ffmpeg detects double frame rate for raw H.264 streams
+        is->video_st->codec->time_base.num = 2;
+
         is->frame_last_filter_delay = av_gettime() / 1000000.0 - is->frame_last_returned_time;
         if (fabs(is->frame_last_filter_delay) > AV_NOSYNC_THRESHOLD / 10.0)
             is->frame_last_filter_delay = 0;
@@ -1927,6 +2003,7 @@ static int video_thread(void *arg)
     avfilter_graph_free(&graph);
 #endif
     av_free(frame);
+    atlas_job_queue_terminate(video_thread);
     return 0;
 }
 
@@ -2272,6 +2349,7 @@ static int stream_component_open(VideoState *is, int stream_index)
         case AVMEDIA_TYPE_AUDIO   : is->last_audio_stream    = stream_index; if(audio_codec_name   ) codec= avcodec_find_decoder_by_name(   audio_codec_name); break;
         case AVMEDIA_TYPE_SUBTITLE: is->last_subtitle_stream = stream_index; if(subtitle_codec_name) codec= avcodec_find_decoder_by_name(subtitle_codec_name); break;
         case AVMEDIA_TYPE_VIDEO   : is->last_video_stream    = stream_index; if(video_codec_name   ) codec= avcodec_find_decoder_by_name(   video_codec_name); break;
+        default:;  // warning fix
     }
     if (!codec)
         return -1;
@@ -2379,8 +2457,15 @@ static int stream_component_open(VideoState *is, int stream_index)
         is->video_stream = stream_index;
         is->video_st = ic->streams[stream_index];
 
+        pthread_mutex_lock(&video_barrier_mutex);
+        pthread_cond_init(&video_barrier, NULL);
+
         packet_queue_start(&is->videoq);
         is->video_tid = SDL_CreateThread(video_thread, is);
+
+        pthread_cond_wait(&video_barrier, &video_barrier_mutex);
+        pthread_mutex_unlock(&video_barrier_mutex);
+        pthread_cond_destroy(&video_barrier);
         break;
     case AVMEDIA_TYPE_SUBTITLE:
         is->subtitle_stream = stream_index;
@@ -2425,7 +2510,10 @@ static void stream_component_close(VideoState *is, int stream_index)
             is->rdft_bits = 0;
         }
         break;
-    case AVMEDIA_TYPE_VIDEO:
+    case AVMEDIA_TYPE_VIDEO:;
+        double metrics[METRICS_COUNT] = { 0.0 };
+        atlas_job_submit_relative(video_thread, 0.0, METRICS_COUNT, metrics);
+
         packet_queue_abort(&is->videoq);
 
         /* note: we also signal this mutex to make sure we deblock the
@@ -2493,10 +2581,13 @@ static int read_thread(void *arg)
     AVPacket pkt1, *pkt = &pkt1;
     int eof = 0;
     int pkt_in_play_range = 0;
+    nalu_read_t *nalu = nalu_read_alloc();
     AVDictionaryEntry *t;
     AVDictionary **opts;
     int orig_nb_streams;
 
+    atlas_job_queue_checkin(read_thread);
+
     memset(st_index, -1, sizeof(st_index));
     is->last_video_stream = is->video_stream = -1;
     is->last_audio_stream = is->audio_stream = -1;
@@ -2605,6 +2696,10 @@ static int read_thread(void *arg)
     }
 
     for (;;) {
+        double deadline = is->frame_timer + is->videoq.nb_packets / 2 * av_q2d(is->video_st->codec->time_base);
+        atlas_job_submit_absolute(read_thread, deadline, 0, NULL);
+        atlas_job_next(read_thread);
+
         if (is->abort_request)
             break;
         if (is->paused != is->last_paused) {
@@ -2667,6 +2762,10 @@ static int read_thread(void *arg)
                 pkt->data = NULL;
                 pkt->size = 0;
                 pkt->stream_index = is->video_stream;
+                
+                double metrics[METRICS_COUNT] = { 0.0 };
+                atlas_job_submit_relative(video_thread, 0.0, METRICS_COUNT, metrics);
+                
                 packet_queue_put(&is->videoq, pkt);
             }
             if (is->audio_stream >= 0 &&
@@ -2682,6 +2781,9 @@ static int read_thread(void *arg)
                 if (loop != 1 && (!loop || --loop)) {
                     stream_seek(is, start_time != AV_NOPTS_VALUE ? start_time : 0, 0, 0);
                 } else if (autoexit) {
+                    // wait until all frames have been displayed
+                    while (is->videoq.nb_packets + is->pictq_size > 0)
+                        SDL_Delay(100);
                     ret = AVERROR_EOF;
                     goto fail;
                 }
@@ -2707,7 +2809,54 @@ static int read_thread(void *arg)
         if (pkt->stream_index == is->audio_stream && pkt_in_play_range) {
             packet_queue_put(&is->audioq, pkt);
         } else if (pkt->stream_index == is->video_stream && pkt_in_play_range) {
+            /* extract metadata from custom NALU and submit job */
+            double metrics[METRICS_COUNT] = { 0.0 };
+            const uint8_t *metadata;
+            
+            /* the metadata NALU is at the end */
+            for (metadata = pkt->data + pkt->size; metadata >= pkt->data + 4; metadata--)
+                if (metadata[-4] == 0 && metadata[-3] == 0 && metadata[-2] == 1 && metadata[-1] == NAL_METADATA)
+                    break;
+            
+            if (metadata >= pkt->data + 4) {
+#if defined(METRICS_FULL)
+                uint_fast16_t mb_width, mb_height;
+                uint_fast8_t slice_count;
+                uint_fast8_t slice_type;
+
+                nalu_read_start(nalu, metadata);
+                mb_width = nalu_read_uint16(nalu);
+                mb_height = nalu_read_uint16(nalu);
+                metrics[0] = mb_width * mb_height;
+                slice_count = nalu_read_uint8(nalu);
+                for (; slice_count; slice_count--) {
+                    slice_type = nalu_read_uint8(nalu);
+                    assert(METRICS_COUNT == 12);
+                    for (size_t i = 1; i < 12; i++)
+                        metrics[i] += nalu_read_uint24(nalu);
+                }
+#elif defined(METRICS_REDUCED)
+                uint_fast16_t mb_width, mb_height;
+                uint_fast8_t slice_count;
+                uint_fast8_t slice_type;
+
+                nalu_read_start(nalu, metadata);
+                mb_width = nalu_read_uint16(nalu);
+                mb_height = nalu_read_uint16(nalu);
+                slice_count = nalu_read_uint8(nalu);
+                slice_type = nalu_read_uint8(nalu);
+                metrics[0] = mb_width * mb_height;
+                metrics[1] = pkt->size;
+                metrics[2] = (slice_type == 0);
+                metrics[3] = (slice_type == 1);
+                metrics[4] = (slice_type == 2);
+#endif
+            }
+            
             packet_queue_put(&is->videoq, pkt);
+            
+            double deadline = is->frame_timer + (is->videoq.nb_packets + is->pictq_size / 2) * av_q2d(is->video_st->codec->time_base);
+            atlas_job_submit_absolute(video_thread, deadline, METRICS_COUNT, metrics);
         } else if (pkt->stream_index == is->subtitle_stream && pkt_in_play_range) {
             packet_queue_put(&is->subtitleq, pkt);
         } else {
@@ -2731,6 +2880,7 @@ static int read_thread(void *arg)
     if (is->ic) {
         avformat_close_input(&is->ic);
     }
+    nalu_read_free(nalu);
 
     if (ret != 0) {
         SDL_Event event;
@@ -2739,9 +2889,19 @@ static int read_thread(void *arg)
         event.user.data1 = is;
         SDL_PushEvent(&event);
     }
+    atlas_job_queue_terminate(read_thread);
     return 0;
 }
 
+/* translate code pointers to human-readable names or numerical ids */
+struct stages_s ffplay_stages[] = {
+    { .code = read_thread, .name = "input", .id = 1 },
+    { .code = video_thread, .name = "decoder", .id = 2 },
+    { .code = refresh_thread, .name = "refresh", .id = 3 },
+    { .code = video_refresh, .name = "output", .id = 4 },
+    { .code = NULL, .name = NULL, .id = 0 }
+};
+
 static VideoState *stream_open(const char *filename, AVInputFormat *iformat)
 {
     VideoState *is;
@@ -2872,6 +3032,8 @@ static void event_loop(VideoState *cur_stream)
 {
     SDL_Event event;
     double incr, pos, frac;
+    
+    atlas_job_queue_checkin(video_refresh);
 
     for (;;) {
         double x;
@@ -3007,6 +3169,8 @@ static void event_loop(VideoState *cur_stream)
             alloc_picture(event.user.data1);
             break;
         case FF_REFRESH_EVENT:
+            if (event.user.code)
+                atlas_job_next(video_refresh);
             video_refresh(event.user.data1);
             cur_stream->refresh = 0;
             break;
@@ -3250,7 +3414,7 @@ int main(int argc, char **argv)
     }
 
     if (display_disable) {
-        video_disable = 1;
+//        video_disable = 1;  keep decoding enabled
     }
     flags = SDL_INIT_VIDEO | SDL_INIT_AUDIO | SDL_INIT_TIMER;
     if (audio_disable)
@@ -3282,7 +3446,7 @@ int main(int argc, char **argv)
     }
 
     av_init_packet(&flush_pkt);
-    flush_pkt.data = (char *)(intptr_t)"FLUSH";
+    flush_pkt.data = (uint8_t *)(intptr_t)"FLUSH";  // warning fix
 
     is = stream_open(input_filename, file_iformat);
     if (!is) {
diff --git a/libavcodec/avcodec.h b/libavcodec/avcodec.h
index 96ca401..bff3857 100644
--- a/libavcodec/avcodec.h
+++ b/libavcodec/avcodec.h
@@ -2914,6 +2914,93 @@ typedef struct AVCodecContext {
     int64_t pts_correction_num_faulty_dts; /// Number of incorrect DTS values so far
     int64_t pts_correction_last_pts;       /// PTS of the last frame
     int64_t pts_correction_last_dts;       /// DTS of the last frame
+
+    /* callback for external slice processing */
+    void (*process_slice)(void *);
+    /* callback for metadata processing */
+    void (*process_metadata)(const uint8_t *);
+    /* callback for external macroblock processing */
+    void (*process_mb)(void *);
+
+    /* NALU type number for our custom metadata NALUs */
+#define NAL_METADATA   0x1F
+    /* pseudo slices */
+#define PSEUDO_SLICE_FRAME_START  -1
+#define PSEUDO_SLICE_FRAME_END    -2
+
+    /* the metrics for the decoding time estimation */
+    /* toggle metrics extraction */
+#define FFMPEG_METRICS 1
+#if FFMPEG_METRICS
+#   define FFMPEG_METRICS_EXTRACT(x) x
+#else
+#   define FFMPEG_METRICS_EXTRACT(x)
+#endif
+    struct {
+        int type;
+        int bits;
+        int intra_pcm;
+        int intra_4x4;
+        int intra_8x8;
+        int intra_16x16;
+        int inter_4x4;
+        int inter_8x8;
+        int inter_16x16;
+        int idct_4x4;
+        int idct_8x8;
+        int deblock_edges;
+    } metrics;
+
+    /* time measurements */
+    /* toggle time measurement */
+#define FFMPEG_TIME 0
+#if FFMPEG_TIME
+#   define FFMPEG_TIME_START(context,slot) context->timing.slot -= read_time()
+#   define FFMPEG_TIME_STOP(context,slot) context->timing.slot += read_time()
+#else
+#   define FFMPEG_TIME_START(context,slot)
+#   define FFMPEG_TIME_STOP(context,slot)
+#endif
+    struct {
+        uint64_t decoder_prep;      /* cabac init */
+        uint64_t decompress_cabac;  /* decode_mb_cabac, includes iscan and iquant */
+        uint64_t decompress_cavlc;  /* decode_mb_cavlc, includes iscan and iquant */
+        uint64_t spatial_pred;      /* pred4x4, pred8x8, pred8x8l, pred16x16 */
+        uint64_t temporal_pred;     /* hl_motion */
+        uint64_t idct;              /* idct and merge */
+        uint64_t post;              /* xchg_mb_border, filter_mb */
+        uint64_t frame_end;         /* execute_ref_pic_marking, ff_er_frame_end, MPV_frame_end */
+        uint64_t total;
+    } timing;
+
+    /* frame structure */
+    struct {
+        int flag_idr;
+        AVFrame *current;
+        AVFrame *display;
+        int mb_width;
+        int mb_height;
+    } frame;
+
+    /* slice structure; does not support FMO */
+    struct {
+        int flag_last;
+        int start_index;  /* macroblock numbers, start inclusive, end exclusive */
+        int end_index;
+        int skip;         /* in-parameter to skip the next slice */
+        int conceal;      /* in-parameter to activate FFmpeg's error concealment */
+    } slice;
+
+    /* reference structure */
+    struct {
+        int long_count;
+        int short_count;
+        AVFrame *long_list[32];
+        AVFrame *short_list[32];
+        int count[2];
+        AVFrame *list[2][32];
+    } reference;
+
 } AVCodecContext;
 
 /**
diff --git a/libavcodec/h264.c b/libavcodec/h264.c
index 22f5527..7a517f6 100644
--- a/libavcodec/h264.c
+++ b/libavcodec/h264.c
@@ -70,6 +70,17 @@ static const enum PixelFormat hwaccel_pixfmt_list_h264_jpeg_420[] = {
     PIX_FMT_NONE
 };
 
+FFMPEG_METRICS_EXTRACT(static int *inter_type);
+static const int qpel_luma_cost[] = {
+    1, 10,  6, 10,
+    10,  6,  7,  6,
+    6,  7,  6,  7,
+    10,  6,  7,  6
+};
+static const int qpel_chroma_cost[] = {
+    2, 4, 8
+};
+
 /**
  * Check if the top & left blocks are available if needed and
  * change the dc mode so it only uses the available blocks.
@@ -497,6 +508,8 @@ static av_always_inline void mc_dir_part(H264Context *h, Picture *pic,
         emu   = 1;
     }
 
+    FFMPEG_METRICS_EXTRACT(*inter_type += (1 + !square) * (qpel_luma_cost[luma_xy] + qpel_chroma_cost[!!(mx&7)+!!(my&7)]));
+
     qpix_op[luma_xy](dest_y, src_y, h->mb_linesize); // FIXME try variable height perhaps?
     if (!square)
         qpix_op[luma_xy](dest_y + delta, src_y + delta, h->mb_linesize);
@@ -796,12 +809,14 @@ static av_always_inline void hl_motion(H264Context *h, uint8_t *dest_y,
     prefetch_motion(h, 0, pixel_shift, chroma_idc);
 
     if (IS_16X16(mb_type)) {
+        FFMPEG_METRICS_EXTRACT(inter_type = &s->avctx->metrics.inter_16x16);
         mc_part(h, 0, 1, 16, 0, dest_y, dest_cb, dest_cr, 0, 0,
                 qpix_put[0], chroma_put[0], qpix_avg[0], chroma_avg[0],
                 weight_op, weight_avg,
                 IS_DIR(mb_type, 0, 0), IS_DIR(mb_type, 0, 1),
                 pixel_shift, chroma_idc);
     } else if (IS_16X8(mb_type)) {
+        FFMPEG_METRICS_EXTRACT(inter_type = &s->avctx->metrics.inter_8x8);
         mc_part(h, 0, 0, 8, 8 << pixel_shift, dest_y, dest_cb, dest_cr, 0, 0,
                 qpix_put[1], chroma_put[0], qpix_avg[1], chroma_avg[0],
                 weight_op, weight_avg,
@@ -813,6 +828,7 @@ static av_always_inline void hl_motion(H264Context *h, uint8_t *dest_y,
                 IS_DIR(mb_type, 1, 0), IS_DIR(mb_type, 1, 1),
                 pixel_shift, chroma_idc);
     } else if (IS_8X16(mb_type)) {
+        FFMPEG_METRICS_EXTRACT(inter_type = &s->avctx->metrics.inter_8x8);
         mc_part(h, 0, 0, 16, 8 * h->mb_linesize, dest_y, dest_cb, dest_cr, 0, 0,
                 qpix_put[1], chroma_put[1], qpix_avg[1], chroma_avg[1],
                 &weight_op[1], &weight_avg[1],
@@ -835,6 +851,7 @@ static av_always_inline void hl_motion(H264Context *h, uint8_t *dest_y,
             int y_offset = (i & 2) << 1;
 
             if (IS_SUB_8X8(sub_mb_type)) {
+                FFMPEG_METRICS_EXTRACT(inter_type = &s->avctx->metrics.inter_8x8);
                 mc_part(h, n, 1, 8, 0, dest_y, dest_cb, dest_cr,
                         x_offset, y_offset,
                         qpix_put[1], chroma_put[1], qpix_avg[1], chroma_avg[1],
@@ -842,6 +859,7 @@ static av_always_inline void hl_motion(H264Context *h, uint8_t *dest_y,
                         IS_DIR(sub_mb_type, 0, 0), IS_DIR(sub_mb_type, 0, 1),
                         pixel_shift, chroma_idc);
             } else if (IS_SUB_8X4(sub_mb_type)) {
+                FFMPEG_METRICS_EXTRACT(inter_type = &s->avctx->metrics.inter_4x4);
                 mc_part(h, n, 0, 4, 4 << pixel_shift, dest_y, dest_cb, dest_cr,
                         x_offset, y_offset,
                         qpix_put[2], chroma_put[1], qpix_avg[2], chroma_avg[1],
@@ -855,6 +873,7 @@ static av_always_inline void hl_motion(H264Context *h, uint8_t *dest_y,
                         IS_DIR(sub_mb_type, 0, 0), IS_DIR(sub_mb_type, 0, 1),
                         pixel_shift, chroma_idc);
             } else if (IS_SUB_4X8(sub_mb_type)) {
+                FFMPEG_METRICS_EXTRACT(inter_type = &s->avctx->metrics.inter_4x4);
                 mc_part(h, n, 0, 8, 4 * h->mb_linesize,
                         dest_y, dest_cb, dest_cr, x_offset, y_offset,
                         qpix_put[2], chroma_put[2], qpix_avg[2], chroma_avg[2],
@@ -870,6 +889,7 @@ static av_always_inline void hl_motion(H264Context *h, uint8_t *dest_y,
             } else {
                 int j;
                 assert(IS_SUB_4X4(sub_mb_type));
+                FFMPEG_METRICS_EXTRACT(inter_type = &s->avctx->metrics.inter_4x4);
                 for (j = 0; j < 4; j++) {
                     int sub_x_offset = x_offset + 2 * (j & 1);
                     int sub_y_offset = y_offset + (j & 2);
@@ -1901,20 +1921,28 @@ static av_always_inline void hl_decode_mb_predict_luma(H264Context *h,
                     idct_add    = h->h264dsp.h264_idct8_add;
                 }
                 for (i = 0; i < 16; i += 4) {
+                    FFMPEG_METRICS_EXTRACT(s->avctx->metrics.intra_8x8++);
                     uint8_t *const ptr = dest_y + block_offset[i];
                     const int dir      = h->intra4x4_pred_mode_cache[scan8[i]];
                     if (transform_bypass && h->sps.profile_idc == 244 && dir <= 1) {
+                        FFMPEG_TIME_START(s->avctx, spatial_pred);
                         h->hpc.pred8x8l_add[dir](ptr, h->mb + (i * 16 + p * 256 << pixel_shift), linesize);
+                        FFMPEG_TIME_STOP(s->avctx, spatial_pred);
                     } else {
                         const int nnz = h->non_zero_count_cache[scan8[i + p * 16]];
+                        FFMPEG_TIME_START(s->avctx, spatial_pred);
                         h->hpc.pred8x8l[dir](ptr, (h->topleft_samples_available << i) & 0x8000,
                                              (h->topright_samples_available << i) & 0x4000, linesize);
+                        FFMPEG_TIME_STOP(s->avctx, spatial_pred);
+                        FFMPEG_TIME_START(s->avctx, idct);
                         if (nnz) {
+                            FFMPEG_METRICS_EXTRACT(transform_bypass ? 0 : s->avctx->metrics.idct_8x8++);
                             if (nnz == 1 && dctcoef_get(h->mb, pixel_shift, i * 16 + p * 256))
                                 idct_dc_add(ptr, h->mb + (i * 16 + p * 256 << pixel_shift), linesize);
                             else
                                 idct_add(ptr, h->mb + (i * 16 + p * 256 << pixel_shift), linesize);
                         }
+                        FFMPEG_TIME_STOP(s->avctx, idct);
                     }
                 }
             } else {
@@ -1926,11 +1954,14 @@ static av_always_inline void hl_decode_mb_predict_luma(H264Context *h,
                     idct_add    = h->h264dsp.h264_idct_add;
                 }
                 for (i = 0; i < 16; i++) {
+                    FFMPEG_METRICS_EXTRACT(s->avctx->metrics.intra_4x4++);
                     uint8_t *const ptr = dest_y + block_offset[i];
                     const int dir      = h->intra4x4_pred_mode_cache[scan8[i]];
 
                     if (transform_bypass && h->sps.profile_idc == 244 && dir <= 1) {
+                        FFMPEG_TIME_START(s->avctx, spatial_pred);
                         h->hpc.pred4x4_add[dir](ptr, h->mb + (i * 16 + p * 256 << pixel_shift), linesize);
+                        FFMPEG_TIME_STOP(s->avctx, spatial_pred);
                     } else {
                         uint8_t *topright;
                         int nnz, tr;
@@ -1951,10 +1982,14 @@ static av_always_inline void hl_decode_mb_predict_luma(H264Context *h,
                         } else
                             topright = NULL;
 
+                        FFMPEG_TIME_START(s->avctx, spatial_pred);
                         h->hpc.pred4x4[dir](ptr, topright, linesize);
+                        FFMPEG_TIME_STOP(s->avctx, spatial_pred);
+                        FFMPEG_TIME_START(s->avctx, idct);
                         nnz = h->non_zero_count_cache[scan8[i + p * 16]];
                         if (nnz) {
                             if (is_h264) {
+                                FFMPEG_METRICS_EXTRACT(transform_bypass ? 0 : s->avctx->metrics.idct_4x4++);
                                 if (nnz == 1 && dctcoef_get(h->mb, pixel_shift, i * 16 + p * 256))
                                     idct_dc_add(ptr, h->mb + (i * 16 + p * 256 << pixel_shift), linesize);
                                 else
@@ -1962,12 +1997,17 @@ static av_always_inline void hl_decode_mb_predict_luma(H264Context *h,
                             } else if (CONFIG_SVQ3_DECODER)
                                 ff_svq3_add_idct_c(ptr, h->mb + i * 16 + p * 256, linesize, qscale, 0);
                         }
+                        FFMPEG_TIME_STOP(s->avctx, idct);
                     }
                 }
             }
         }
     } else {
+        FFMPEG_METRICS_EXTRACT(s->avctx->metrics.intra_16x16++);
+        FFMPEG_TIME_START(s->avctx, spatial_pred);
         h->hpc.pred16x16[h->intra16x16_pred_mode](dest_y, linesize);
+        FFMPEG_TIME_STOP(s->avctx, spatial_pred);
+        FFMPEG_TIME_START(s->avctx, idct);
         if (is_h264) {
             if (h->non_zero_count_cache[scan8[LUMA_DC_BLOCK_INDEX + p]]) {
                 if (!transform_bypass)
@@ -1990,6 +2030,7 @@ static av_always_inline void hl_decode_mb_predict_luma(H264Context *h,
         } else if (CONFIG_SVQ3_DECODER)
             ff_svq3_luma_dc_dequant_idct_c(h->mb + p * 256,
                                            h->mb_luma_dc[p], qscale);
+        FFMPEG_TIME_STOP(s->avctx, idct);
     }
 }
 
@@ -2012,34 +2053,46 @@ static av_always_inline void hl_decode_mb_idct_luma(H264Context *h, int mb_type,
                     if (h->sps.profile_idc == 244 &&
                         (h->intra16x16_pred_mode == VERT_PRED8x8 ||
                          h->intra16x16_pred_mode == HOR_PRED8x8)) {
+                        FFMPEG_METRICS_EXTRACT(s->avctx->metrics.intra_16x16++);
+                        FFMPEG_TIME_START(s->avctx, spatial_pred);
                         h->hpc.pred16x16_add[h->intra16x16_pred_mode](dest_y, block_offset,
                                                                       h->mb + (p * 256 << pixel_shift),
                                                                       linesize);
+                        FFMPEG_TIME_STOP(s->avctx, spatial_pred);
                     } else {
+                        FFMPEG_TIME_START(s->avctx, idct);
                         for (i = 0; i < 16; i++)
                             if (h->non_zero_count_cache[scan8[i + p * 16]] ||
                                 dctcoef_get(h->mb, pixel_shift, i * 16 + p * 256))
                                 s->dsp.add_pixels4(dest_y + block_offset[i],
                                                    h->mb + (i * 16 + p * 256 << pixel_shift),
                                                    linesize);
+                        FFMPEG_TIME_STOP(s->avctx, idct);
                     }
                 } else {
+                    FFMPEG_METRICS_EXTRACT(s->avctx->metrics.idct_4x4 += 16);
+                    FFMPEG_TIME_START(s->avctx, idct);
                     h->h264dsp.h264_idct_add16intra(dest_y, block_offset,
                                                     h->mb + (p * 256 << pixel_shift),
                                                     linesize,
                                                     h->non_zero_count_cache + p * 5 * 8);
+                    FFMPEG_TIME_STOP(s->avctx, idct);
                 }
             } else if (h->cbp & 15) {
                 if (transform_bypass) {
                     const int di = IS_8x8DCT(mb_type) ? 4 : 1;
                     idct_add = IS_8x8DCT(mb_type) ? s->dsp.add_pixels8
                                                   : s->dsp.add_pixels4;
+                    FFMPEG_TIME_START(s->avctx, idct);
                     for (i = 0; i < 16; i += di)
                         if (h->non_zero_count_cache[scan8[i + p * 16]])
                             idct_add(dest_y + block_offset[i],
                                      h->mb + (i * 16 + p * 256 << pixel_shift),
                                      linesize);
+                    FFMPEG_TIME_STOP(s->avctx, idct);
                 } else {
+                    FFMPEG_METRICS_EXTRACT(IS_8x8DCT(mb_type) ? (s->avctx->metrics.idct_8x8 += 4) : (s->avctx->metrics.idct_4x4 += 16));
+                    FFMPEG_TIME_START(s->avctx, idct);
                     if (IS_8x8DCT(mb_type))
                         h->h264dsp.h264_idct8_add4(dest_y, block_offset,
                                                    h->mb + (p * 256 << pixel_shift),
@@ -2050,6 +2103,7 @@ static av_always_inline void hl_decode_mb_idct_luma(H264Context *h, int mb_type,
                                                    h->mb + (p * 256 << pixel_shift),
                                                    linesize,
                                                    h->non_zero_count_cache + p * 5 * 8);
+                    FFMPEG_TIME_STOP(s->avctx, idct);
                 }
             }
         } else if (CONFIG_SVQ3_DECODER) {
@@ -2126,6 +2180,7 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
     }
 
     if (!simple && IS_INTRA_PCM(mb_type)) {
+        FFMPEG_METRICS_EXTRACT(s->avctx->metrics.intra_pcm++);
         const int bit_depth = h->sps.bit_depth_luma;
         if (pixel_shift) {
             int j;
@@ -2181,14 +2236,18 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
         }
     } else {
         if (IS_INTRA(mb_type)) {
+            FFMPEG_TIME_START(s->avctx, post);
             if (h->deblocking_filter)
                 xchg_mb_border(h, dest_y, dest_cb, dest_cr, linesize,
                                uvlinesize, 1, 0, simple, pixel_shift);
+            FFMPEG_TIME_STOP(s->avctx, post);
 
             if (simple || !CONFIG_GRAY || !(s->flags & CODEC_FLAG_GRAY)) {
                 if (CHROMA) {
+                    FFMPEG_TIME_START(s->avctx, spatial_pred);
                     h->hpc.pred8x8[h->chroma_pred_mode](dest_cb, uvlinesize);
                     h->hpc.pred8x8[h->chroma_pred_mode](dest_cr, uvlinesize);
+                    FFMPEG_TIME_STOP(s->avctx, spatial_pred);
                 }
             }
 
@@ -2196,10 +2255,13 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
                                       transform_bypass, pixel_shift,
                                       block_offset, linesize, dest_y, 0);
 
+            FFMPEG_TIME_START(s->avctx, post);
             if (h->deblocking_filter)
                 xchg_mb_border(h, dest_y, dest_cb, dest_cr, linesize,
                                uvlinesize, 0, 0, simple, pixel_shift);
+            FFMPEG_TIME_STOP(s->avctx, post);
         } else if (is_h264) {
+            FFMPEG_TIME_START(s->avctx, temporal_pred);
             if (chroma422) {
                 hl_motion_422(h, dest_y, dest_cb, dest_cr,
                               s->me.qpel_put, s->dsp.put_h264_chroma_pixels_tab,
@@ -2215,6 +2277,7 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
                               h->h264dsp.biweight_h264_pixels_tab,
                               pixel_shift);
             }
+            FFMPEG_TIME_STOP(s->avctx, temporal_pred);
         }
 
         hl_decode_mb_idct_luma(h, mb_type, is_h264, simple, transform_bypass,
@@ -2227,6 +2290,7 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
                 if (IS_INTRA(mb_type) && h->sps.profile_idc == 244 &&
                     (h->chroma_pred_mode == VERT_PRED8x8 ||
                      h->chroma_pred_mode == HOR_PRED8x8)) {
+                    FFMPEG_TIME_START(s->avctx, spatial_pred);
                     h->hpc.pred8x8_add[h->chroma_pred_mode](dest[0],
                                                             block_offset + 16,
                                                             h->mb + (16 * 16 * 1 << pixel_shift),
@@ -2235,8 +2299,10 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
                                                             block_offset + 32,
                                                             h->mb + (16 * 16 * 2 << pixel_shift),
                                                             uvlinesize);
+                    FFMPEG_TIME_STOP(s->avctx, spatial_pred);
                 } else {
                     idct_add = s->dsp.add_pixels4;
+                    FFMPEG_TIME_START(s->avctx, idct);
                     for (j = 1; j < 3; j++) {
                         for (i = j * 16; i < j * 16 + 4; i++)
                             if (h->non_zero_count_cache[scan8[i]] ||
@@ -2253,6 +2319,7 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
                                              uvlinesize);
                         }
                     }
+                    FFMPEG_TIME_STOP(s->avctx, idct);
                 }
             } else {
                 if (is_h264) {
@@ -2264,6 +2331,8 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
                         qp[0] = h->chroma_qp[0];
                         qp[1] = h->chroma_qp[1];
                     }
+                    FFMPEG_METRICS_EXTRACT(s->avctx->metrics.idct_4x4 += 8);
+                    FFMPEG_TIME_START(s->avctx, idct);
                     if (h->non_zero_count_cache[scan8[CHROMA_DC_BLOCK_INDEX + 0]])
                         h->h264dsp.h264_chroma_dc_dequant_idct(h->mb + (16 * 16 * 1 << pixel_shift),
                                                                h->dequant4_coeff[IS_INTRA(mb_type) ? 1 : 4][qp[0]][0]);
@@ -2273,6 +2342,7 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
                     h->h264dsp.h264_idct_add8(dest, block_offset,
                                               h->mb, uvlinesize,
                                               h->non_zero_count_cache);
+                    FFMPEG_TIME_STOP(s->avctx, idct);
                 } else if (CONFIG_SVQ3_DECODER) {
                     h->h264dsp.h264_chroma_dc_dequant_idct(h->mb + 16 * 16 * 1,
                                                            h->dequant4_coeff[IS_INTRA(mb_type) ? 1 : 4][h->chroma_qp[0]][0]);
@@ -2351,6 +2421,7 @@ static av_always_inline void hl_decode_mb_444_internal(H264Context *h,
     }
 
     if (!simple && IS_INTRA_PCM(mb_type)) {
+        FFMPEG_METRICS_EXTRACT(s->avctx->metrics.intra_pcm++);
         if (pixel_shift) {
             const int bit_depth = h->sps.bit_depth_luma;
             GetBitContext gb;
@@ -2370,24 +2441,30 @@ static av_always_inline void hl_decode_mb_444_internal(H264Context *h,
         }
     } else {
         if (IS_INTRA(mb_type)) {
+            FFMPEG_TIME_START(s->avctx, post);
             if (h->deblocking_filter)
                 xchg_mb_border(h, dest[0], dest[1], dest[2], linesize,
                                linesize, 1, 1, simple, pixel_shift);
+            FFMPEG_TIME_STOP(s->avctx, post);
 
             for (p = 0; p < plane_count; p++)
                 hl_decode_mb_predict_luma(h, mb_type, 1, simple,
                                           transform_bypass, pixel_shift,
                                           block_offset, linesize, dest[p], p);
 
+            FFMPEG_TIME_START(s->avctx, post);
             if (h->deblocking_filter)
                 xchg_mb_border(h, dest[0], dest[1], dest[2], linesize,
                                linesize, 0, 1, simple, pixel_shift);
+            FFMPEG_TIME_STOP(s->avctx, post);
         } else {
+            FFMPEG_TIME_START(s->avctx, temporal_pred);
             hl_motion(h, dest[0], dest[1], dest[2],
                       s->me.qpel_put, s->dsp.put_h264_chroma_pixels_tab,
                       s->me.qpel_avg, s->dsp.avg_h264_chroma_pixels_tab,
                       h->h264dsp.weight_h264_pixels_tab,
                       h->h264dsp.biweight_h264_pixels_tab, pixel_shift, 3);
+            FFMPEG_TIME_STOP(s->avctx, temporal_pred);
         }
 
         for (p = 0; p < plane_count; p++)
@@ -3871,6 +3948,7 @@ static void loop_filter(H264Context *h, int start_x, int end_x)
     const int pixel_shift    = h->pixel_shift;
     const int block_h        = 16 >> s->chroma_y_shift;
 
+    FFMPEG_TIME_START(s->avctx, post);
     if (h->deblocking_filter) {
         for (mb_x = start_x; mb_x < end_x; mb_x++)
             for (mb_y = end_mb_y - FRAME_MBAFF; mb_y <= end_mb_y; mb_y++) {
@@ -3924,6 +4002,7 @@ static void loop_filter(H264Context *h, int start_x, int end_x)
                 }
             }
     }
+    FFMPEG_TIME_STOP(s->avctx, post);
     h->slice_type   = old_slice_type;
     s->mb_x         = end_x;
     s->mb_y         = end_mb_y - FRAME_MBAFF;
@@ -3984,7 +4063,49 @@ static int decode_slice(struct AVCodecContext *avctx, void *arg)
     const int part_mask     = s->partitioned_frame ? (ER_AC_END | ER_AC_ERROR)
                                                    : 0x7F;
     int lf_x_start = s->mb_x;
-
+    FFMPEG_METRICS_EXTRACT(unsigned bits_gone_by = 0);
+
+     /* new slice coming up, process previous one */
+    s->avctx->frame.flag_idr  = (h->nal_unit_type == NAL_IDR_SLICE);
+    s->avctx->frame.current   = (AVFrame *)&s->current_picture;
+    s->avctx->frame.mb_width  = s->mb_width;
+    s->avctx->frame.mb_height = s->mb_height;
+    s->avctx->slice.end_index = s->mb_x + s->mb_y * s->mb_width;
+    s->avctx->reference.long_count  = h->long_ref_count;
+    s->avctx->reference.short_count = h->short_ref_count;
+    memcpy(s->avctx->reference.long_list , h->long_ref , sizeof(h->long_ref ));
+    memcpy(s->avctx->reference.short_list, h->short_ref, sizeof(h->short_ref));
+    if (s->avctx->slice.skip && !s->avctx->slice.conceal)
+        // previous slice has been skipped, mark it done so that error resilience does not kick in
+        ff_er_add_slice(s,
+                        s->avctx->slice.start_index % s->mb_width,
+                        s->avctx->slice.start_index / s->mb_width,
+                        s->avctx->slice.end_index % s->mb_width - 1,
+                        s->avctx->slice.end_index / s->mb_width,
+                        ER_MB_END & 0x7F);
+    if (avctx->process_slice) {
+        emms_c();
+        avctx->process_slice(s->avctx);
+    }
+    /* prepare data for upcoming slice */
+    s->avctx->metrics.type = h->slice_type;
+    s->avctx->slice.start_index = s->mb_x + s->mb_y * s->mb_width;
+    s->avctx->reference.count[0] = h->ref_count[0];
+    s->avctx->reference.count[1] = h->ref_count[1];
+    {
+        int i;
+        for (i = 0; i < 32; i++) {
+            s->avctx->reference.list[0][i] = (AVFrame *)&h->ref_list[0][i];
+            s->avctx->reference.list[1][i] = (AVFrame *)&h->ref_list[1][i];
+        }
+    }
+    if (s->avctx->slice.skip) {
+        // do not decode this slice and skip the given amount of macroblocks
+        s->mb_x = (s->avctx->slice.start_index + s->avctx->slice.skip) % s->mb_width;
+        s->mb_y = (s->avctx->slice.start_index + s->avctx->slice.skip) / s->mb_width;
+        return 0;
+    }
+    
     s->mb_skip_run = -1;
 
     h->is_complex = FRAME_MBAFF || s->picture_structure != PICT_FRAME ||
@@ -3996,16 +4117,20 @@ static int decode_slice(struct AVCodecContext *avctx, void *arg)
         align_get_bits(&s->gb);
 
         /* init cabac */
+        FFMPEG_TIME_START(s->avctx, decoder_prep);
         ff_init_cabac_states(&h->cabac);
         ff_init_cabac_decoder(&h->cabac,
                               s->gb.buffer + get_bits_count(&s->gb) / 8,
                               (get_bits_left(&s->gb) + 7) / 8);
 
         ff_h264_init_cabac_states(h);
+        FFMPEG_TIME_STOP(s->avctx, decoder_prep);
 
         for (;;) {
             // START_TIMER
+            FFMPEG_TIME_START(s->avctx, decompress_cabac);
             int ret = ff_h264_decode_mb_cabac(h);
+            FFMPEG_TIME_STOP(s->avctx, decompress_cabac);
             int eos;
             // STOP_TIMER("decode_mb_cabac")
 
@@ -4016,13 +4141,26 @@ static int decode_slice(struct AVCodecContext *avctx, void *arg)
             if (ret >= 0 && FRAME_MBAFF) {
                 s->mb_y++;
 
+                FFMPEG_TIME_START(s->avctx, decompress_cabac);
                 ret = ff_h264_decode_mb_cabac(h);
+                FFMPEG_TIME_STOP(s->avctx, decompress_cabac);
 
                 if (ret >= 0)
                     ff_h264_hl_decode_mb(h);
                 s->mb_y--;
             }
+            FFMPEG_TIME_START(s->avctx, decompress_cabac);
             eos = get_cabac_terminate(&h->cabac);
+            FFMPEG_TIME_STOP(s->avctx, decompress_cabac);
+
+            FFMPEG_METRICS_EXTRACT(s->avctx->metrics.bits -= bits_gone_by);
+            FFMPEG_METRICS_EXTRACT(bits_gone_by = (h->cabac.bytestream - h->cabac.bytestream_start) * 8);
+            FFMPEG_METRICS_EXTRACT(s->avctx->metrics.bits += bits_gone_by);
+
+            if(s->avctx->process_mb) {
+                emms_c();
+                s->avctx->process_mb(s->avctx);
+            }
 
             if ((s->workaround_bugs & FF_BUG_TRUNCATED) &&
                 h->cabac.bytestream > h->cabac.bytestream_end + 2) {
@@ -4068,7 +4206,9 @@ static int decode_slice(struct AVCodecContext *avctx, void *arg)
         }
     } else {
         for (;;) {
+            FFMPEG_TIME_START(s->avctx, decompress_cavlc);
             int ret = ff_h264_decode_mb_cavlc(h);
+            FFMPEG_TIME_STOP(s->avctx, decompress_cavlc);
 
             if (ret >= 0)
                 ff_h264_hl_decode_mb(h);
@@ -4076,13 +4216,24 @@ static int decode_slice(struct AVCodecContext *avctx, void *arg)
             // FIXME optimal? or let mb_decode decode 16x32 ?
             if (ret >= 0 && FRAME_MBAFF) {
                 s->mb_y++;
+                FFMPEG_TIME_START(s->avctx, decompress_cavlc);
                 ret = ff_h264_decode_mb_cavlc(h);
+                FFMPEG_TIME_STOP(s->avctx, decompress_cavlc);
 
                 if (ret >= 0)
                     ff_h264_hl_decode_mb(h);
                 s->mb_y--;
             }
 
+            FFMPEG_METRICS_EXTRACT(s->avctx->metrics.bits -= bits_gone_by);
+            FFMPEG_METRICS_EXTRACT(bits_gone_by = get_bits_count(&s->gb));
+            FFMPEG_METRICS_EXTRACT(s->avctx->metrics.bits += bits_gone_by);
+
+            if(s->avctx->process_mb) {
+                emms_c();
+                s->avctx->process_mb(s->avctx);
+            }
+
             if (ret < 0) {
                 av_log(h->s.avctx, AV_LOG_ERROR,
                        "error while decoding MB %d %d\n", s->mb_x, s->mb_y);
@@ -4450,6 +4601,12 @@ again:
             case NAL_SPS_EXT:
             case NAL_AUXILIARY_SLICE:
                 break;
+            case NAL_METADATA:
+                if (s->avctx->process_metadata) {
+                    emms_c();
+                    s->avctx->process_metadata(ptr);
+                }
+            break;
             default:
                 av_log(avctx, AV_LOG_DEBUG, "Unknown NAL code: %d (%d bits)\n",
                        hx->nal_unit_type, bit_length);
@@ -4543,6 +4700,13 @@ static int decode_frame(AVCodecContext *avctx, void *data,
             *pict      = out->f;
         }
 
+        avctx->metrics.type = PSEUDO_SLICE_FRAME_END;
+        avctx->frame.display = *data_size ? pict : NULL;
+        if (avctx->process_slice) {
+            emms_c();
+            avctx->process_slice(avctx);
+        }
+
         return buf_index;
     }
     if(h->is_avc && buf_size >= 9 && buf[0]==1 && buf[2]==0 && (buf[4]&0xFC)==0xFC && (buf[5]&0x1F) && buf[8]==0x67){
@@ -4567,16 +4731,35 @@ static int decode_frame(AVCodecContext *avctx, void *data,
         return ff_h264_decode_extradata(h, buf, buf_size);
     }
 not_extra:
+    avctx->metrics.type = PSEUDO_SLICE_FRAME_START;
 
     buf_index = decode_nal_units(h, buf, buf_size);
     if (buf_index < 0)
         return -1;
 
+    /* process last slice */
+    s->avctx->slice.flag_last = 1;
+    s->avctx->slice.end_index = s->mb_x + s->mb_y * s->mb_width;
+    if (s->avctx->slice.skip && !s->avctx->slice.conceal)
+        // previous slice has been skipped, mark it done so that error resilience does not kick in
+        ff_er_add_slice(s,
+                        s->avctx->slice.start_index % s->mb_width,
+                        s->avctx->slice.start_index / s->mb_width,
+                        s->avctx->slice.end_index % s->mb_width - 1,
+                        s->avctx->slice.end_index / s->mb_width,
+                        ER_MB_END & 0x7F);
+    if (avctx->process_slice) {
+        emms_c();
+        avctx->process_slice(s->avctx);
+    }
+    avctx->metrics.type = PSEUDO_SLICE_FRAME_END;
+
     if (!s->current_picture_ptr && h->nal_unit_type == NAL_END_SEQUENCE) {
         av_assert0(buf_index <= buf_size);
         goto out;
     }
 
+    FFMPEG_TIME_START(avctx, frame_end);
     if (!(s->flags2 & CODEC_FLAG2_CHUNKS) && !s->current_picture_ptr) {
         if (avctx->skip_frame >= AVDISCARD_NONREF ||
             buf_size >= 4 && !memcmp("Q264", buf, 4))
@@ -4599,6 +4782,14 @@ not_extra:
             *pict      = h->next_output_pic->f;
         }
     }
+    FFMPEG_TIME_STOP(avctx, frame_end);
+
+    /* frame end processing */
+    avctx->frame.display = *data_size ? pict : NULL;
+    if (avctx->process_slice) {
+        emms_c();
+        avctx->process_slice(avctx);
+    }
 
     assert(pict->data[0] || !*data_size);
     ff_print_debug_info(s, pict);
diff --git a/libavcodec/h264_loopfilter.c b/libavcodec/h264_loopfilter.c
index 6395607..7ad5dd7 100644
--- a/libavcodec/h264_loopfilter.c
+++ b/libavcodec/h264_loopfilter.c
@@ -110,6 +110,7 @@ static av_always_inline void filter_mb_edgev(uint8_t *pix, int stride,
     const int alpha = alpha_table[index_a];
     const int beta  = beta_table[qp + b];
     if (alpha ==0 || beta == 0) return;
+    FFMPEG_METRICS_EXTRACT(h->s.avctx->metrics.deblock_edges += 4);
 
     if( bS[0] < 4 || !intra ) {
         int8_t tc[4];
@@ -132,6 +133,7 @@ static av_always_inline void filter_mb_edgecv(uint8_t *pix, int stride,
     const int alpha = alpha_table[index_a];
     const int beta  = beta_table[qp + b];
     if (alpha ==0 || beta == 0) return;
+    FFMPEG_METRICS_EXTRACT(h->s.avctx->metrics.deblock_edges += 2);
 
     if( bS[0] < 4 || !intra ) {
         int8_t tc[4];
@@ -155,6 +157,7 @@ static av_always_inline void filter_mb_mbaff_edgev(H264Context *h, uint8_t *pix,
     const int alpha = alpha_table[index_a];
     const int beta  = beta_table[qp + b];
     if (alpha ==0 || beta == 0) return;
+    FFMPEG_METRICS_EXTRACT(h->s.avctx->metrics.deblock_edges += 2);
 
     if( bS[0] < 4 || !intra ) {
         int8_t tc[4];
@@ -178,6 +181,7 @@ static av_always_inline void filter_mb_mbaff_edgecv(H264Context *h,
     const int alpha = alpha_table[index_a];
     const int beta  = beta_table[qp + b];
     if (alpha ==0 || beta == 0) return;
+    FFMPEG_METRICS_EXTRACT(h->s.avctx->metrics.deblock_edges++);
 
     if( bS[0] < 4 || !intra ) {
         int8_t tc[4];
@@ -200,6 +204,7 @@ static av_always_inline void filter_mb_edgeh(uint8_t *pix, int stride,
     const int alpha = alpha_table[index_a];
     const int beta  = beta_table[qp + b];
     if (alpha ==0 || beta == 0) return;
+    FFMPEG_METRICS_EXTRACT(h->s.avctx->metrics.deblock_edges += 4);
 
     if( bS[0] < 4 || !intra ) {
         int8_t tc[4];
@@ -222,6 +227,7 @@ static av_always_inline void filter_mb_edgech(uint8_t *pix, int stride,
     const int alpha = alpha_table[index_a];
     const int beta  = beta_table[qp + b];
     if (alpha ==0 || beta == 0) return;
+    FFMPEG_METRICS_EXTRACT(h->s.avctx->metrics.deblock_edges += 2);
 
     if( bS[0] < 4 || !intra ) {
         int8_t tc[4];
diff --git a/libavformat/utils.c b/libavformat/utils.c
index ca97b91..6db260b 100644
--- a/libavformat/utils.c
+++ b/libavformat/utils.c
@@ -3853,9 +3853,16 @@ void av_dump_format(AVFormatContext *ic,
 
 int64_t av_gettime(void)
 {
+#ifdef __linux__
+    /* ATLAS uses CLOCK_MONOTONIC as reference, because seconds are always a wallclock second there */
+    struct timespec ts;
+    clock_gettime(CLOCK_MONOTONIC, &ts);
+    return (int64_t)ts.tv_sec * 1000000 + (ts.tv_nsec + 500) / 1000;
+#else
     struct timeval tv;
     gettimeofday(&tv,NULL);
     return (int64_t)tv.tv_sec * 1000000 + tv.tv_usec;
+#endif
 }
 
 uint64_t ff_ntp_time(void)
