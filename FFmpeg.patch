diff --git a/ffplay.c b/ffplay.c
index 779c879..72b1a3a 100644
--- a/ffplay.c
+++ b/ffplay.c
@@ -56,6 +56,23 @@
 
 #include "cmdutils.h"
 
+#include "dispatch.h"
+#include "estimator.h"
+#include "scheduler.h"
+#include "nalu.h"
+
+#if defined(METRICS_NONE)
+# define METRICS_COUNT 0
+#elif defined(METRICS_REDUCED)
+# define METRICS_COUNT 5
+#else
+# define METRICS_FULL 1
+# define METRICS_COUNT 13
+#endif
+
+/* use ATLAS' timebase for playback timing */
+#define av_gettime() (atlas_now() * 1000000.0)
+
 #include <unistd.h>
 #include <assert.h>
 
@@ -126,9 +143,10 @@ enum {
 };
 
 typedef struct VideoState {
-    SDL_Thread *read_tid;
-    SDL_Thread *video_tid;
-    SDL_Thread *refresh_tid;
+    dispatch_queue_t read_queue;
+    dispatch_queue_t video_queue;
+    dispatch_queue_t refresh_queue;
+    pid_t main_thread;
     AVInputFormat *iformat;
     int no_background;
     int abort_request;
@@ -889,17 +907,21 @@ static void video_audio_display(VideoState *s)
     }
 }
 
+static int read_stage(void *arg);
+
 static void stream_close(VideoState *is)
 {
     VideoPicture *vp;
     int i;
     /* XXX: use a special url_shutdown call to abort parse cleanly */
     is->abort_request = 1;
-    SDL_WaitThread(is->read_tid, NULL);
-    SDL_WaitThread(is->refresh_tid, NULL);
+    dispatch_sync(is->read_queue, ^{ read_stage(is); });  // one more run for cleanup
+    dispatch_release(is->read_queue);
     packet_queue_destroy(&is->videoq);
     packet_queue_destroy(&is->audioq);
     packet_queue_destroy(&is->subtitleq);
+    dispatch_sync(is->refresh_queue, ^{});
+    dispatch_release(is->refresh_queue);
 
     /* free all pictures */
     for (i = 0; i < VIDEO_PICTURE_QUEUE_SIZE; i++) {
@@ -1000,17 +1022,48 @@ static void video_display(VideoState *is)
         video_image_display(is);
 }
 
-static int refresh_thread(void *opaque)
+static int refresh_stage(void *opaque)  // called output stage in the thesis
 {
     VideoState *is= opaque;
+    int consume_next_frame = 0;
+
     while (!is->abort_request) {
+        /* match the conditions from video_refresh() here, so we know when the next frame will be consumed there */
+        if (is->refresh)
+            goto throttle;
+        if (is->video_st) {
+            if (is->pictq_size == 0)
+                goto throttle;
+            if (is->paused)
+                goto refresh;
+
+            double frame_duration = is->frame_last_duration;
+            if (frame_duration == 0.0 && is->frame_last_pts != AV_NOPTS_VALUE)
+                /* peek ahead in the picture queue */
+                frame_duration = is->pictq[is->pictq_rindex].pts - is->frame_last_pts;
+
+            int sleep_result = 0;
+            do {
+                double wait = (is->frame_timer + frame_duration) - av_gettime() / 1000000.0;
+                if (wait > 0)
+                    sleep_result = usleep(wait * 1000000);
+            } while (sleep_result < 0);
+
+            consume_next_frame = 1;
+        }
+
+    refresh:;
         SDL_Event event;
         event.type = FF_REFRESH_EVENT;
         event.user.data1 = opaque;
-        if (!is->refresh && (!is->paused || is->force_refresh)) {
+        event.user.code = consume_next_frame;
+        assert(!is->refresh);
+        if (!is->paused || is->force_refresh) {
             is->refresh = 1;
             SDL_PushEvent(&event);
         }
+        if (consume_next_frame) return 0;
+    throttle:
         //FIXME ideally we should wait the correct time but SDLs event passing is so slow it would be silly
         usleep(is->audio_st && is->show_mode != SHOW_MODE_VIDEO ? rdftspeed*1000 : 5000);
     }
@@ -1151,7 +1204,7 @@ static void video_refresh(void *opaque)
     SubPicture *sp, *sp2;
 
     if (is->video_st) {
-retry:
+        assert(is->pictq_size > 0);  // changes to the refresh_thread should ensure we always have a frame
         if (is->pictq_size == 0) {
             SDL_LockMutex(is->pictq_mutex);
             if (is->frame_last_dropped_pts != AV_NOPTS_VALUE && is->frame_last_dropped_pts > is->frame_last_pts) {
@@ -1167,7 +1220,7 @@ retry:
 
             if (vp->skip) {
                 pictq_next_picture(is);
-                goto retry;
+                return;  // only consume one frame at a time, or we will get out of sync with submitted jobs
             }
 
             if (is->paused)
@@ -1182,6 +1235,7 @@ retry:
             delay = compute_target_delay(is->frame_last_duration, is);
 
             time= av_gettime()/1000000.0;
+            assert(time >= is->frame_timer + delay);  // changes to the refresh_thread should ensure we never get here too early
             if (time < is->frame_timer + delay)
                 return;
 
@@ -1203,7 +1257,7 @@ retry:
                 if(is->pictq_size > 1){
                     is->frame_drops_late++;
                     pictq_next_picture(is);
-                    goto retry;
+                    return;  // only consume one frame at a time, or we will get out of sync with submitted jobs
                 }
             }
 
@@ -1477,6 +1531,12 @@ static int queue_picture(VideoState *is, AVFrame *src_frame, double pts1, int64_
         SDL_LockMutex(is->pictq_mutex);
         is->pictq_size++;
         SDL_UnlockMutex(is->pictq_mutex);
+
+        atlas_job_t job = {
+            .deadline = is->frame_timer + is->pictq_size * av_q2d(is->video_st->codec->time_base)
+        };
+        atlas_job_submit(video_refresh, is->main_thread, job);
+        dispatch_async_atlas(is->refresh_queue, job, ^{ refresh_stage(is); });
     }
     return 0;
 }
@@ -1688,8 +1748,14 @@ static int input_request_frame(AVFilterLink *link)
     AVPacket pkt;
     int ret;
 
-    while (!(ret = get_video_frame(priv->is, priv->frame, &pts, &pkt)))
+    do {
+        ret = get_video_frame(priv->is, priv->frame, &pts, &pkt);
+    } while (pkt.data == flush_pkt.data);  // flush packets are not individual jobs, consume collaterally...
+    if (ret == 0) {
+        // ... decoding a packet without receiving a frame however is an individual job, so we must return this state
         av_free_packet(&pkt);
+        return AVERROR(EAGAIN);
+    }
     if (ret < 0)
         return -1;
 
@@ -1775,7 +1841,7 @@ static int configure_video_filters(AVFilterGraph *graph, VideoState *is, const c
 #if FF_API_OLD_VSINK_API
     ret = avfilter_graph_create_filter(&filt_out,
                                        avfilter_get_by_name("buffersink"),
-                                       "out", NULL, pix_fmts, graph);
+                                       "out", NULL, (void *)pix_fmts, graph);  // warning fix
 #else
     buffersink_params->pixel_fmts = pix_fmts;
     ret = avfilter_graph_create_filter(&filt_out,
@@ -1825,29 +1891,43 @@ static int configure_video_filters(AVFilterGraph *graph, VideoState *is, const c
 
 #endif  /* CONFIG_AVFILTER */
 
-static int video_thread(void *arg)
+static int video_stage(void *arg)  // called decoder stage in the thesis
 {
     VideoState *is = arg;
-    AVFrame *frame = avcodec_alloc_frame();
+    static AVFrame *frame;
     int64_t pts_int = AV_NOPTS_VALUE, pos = -1;
     double pts;
     int ret;
 
 #if CONFIG_AVFILTER
-    AVFilterGraph *graph = avfilter_graph_alloc();
-    AVFilterContext *filt_out = NULL;
-    int last_w = is->video_st->codec->width;
-    int last_h = is->video_st->codec->height;
+    static AVFilterGraph *graph;
+    static AVFilterContext *filt_out;
+    static int last_w;
+    static int last_h;
+#endif
+
+static dispatch_once_t predicate;
+dispatch_once(&predicate, ^{
+    frame = avcodec_alloc_frame();
+#if CONFIG_AVFILTER
+    graph = avfilter_graph_alloc();
+    filt_out = NULL;
+    last_w = is->video_st->codec->width;
+    last_h = is->video_st->codec->height;
 
-    if ((ret = configure_video_filters(graph, is, vfilters)) < 0) {
+    if (configure_video_filters(graph, is, vfilters) < 0) {
         SDL_Event event;
         event.type = FF_QUIT_EVENT;
         event.user.data1 = is;
         SDL_PushEvent(&event);
-        goto the_end;
     }
     filt_out = is->out_video_filter;
 #endif
+});
+    if (!filt_out)
+        goto the_end;
+    if (!graph)
+        return 0;  // the cleanup code already ran before
 
     for (;;) {
 #if !CONFIG_AVFILTER
@@ -1872,6 +1952,8 @@ static int video_thread(void *arg)
             last_h = is->video_st->codec->height;
         }
         ret = av_buffersink_get_buffer_ref(filt_out, &picref, 0);
+        if (ret == AVERROR(EAGAIN))
+            return 0;  // we decoded a packet resulting in no frame; job complete
         if (picref) {
             avfilter_fill_frame_from_video_buffer_ref(frame, picref);
             pts_int = picref->pts;
@@ -1895,19 +1977,22 @@ static int video_thread(void *arg)
         pos = pkt.pos;
         av_free_packet(&pkt);
         if (ret == 0)
-            continue;
+            return 0;  // job complete
 #endif
 
         if (ret < 0)
             goto the_end;
 
+        // ffmpeg detects double frame rate for raw H.264 streams
+        is->video_st->codec->time_base.num = 2;
+
         is->frame_last_filter_delay = av_gettime() / 1000000.0 - is->frame_last_returned_time;
         if (fabs(is->frame_last_filter_delay) > AV_NOSYNC_THRESHOLD / 10.0)
             is->frame_last_filter_delay = 0;
 
 #if CONFIG_AVFILTER
         if (!picref)
-            continue;
+            return 0;  // job complete
 #endif
 
         pts = pts_int * av_q2d(is->video_st->time_base);
@@ -1919,6 +2004,8 @@ static int video_thread(void *arg)
 
         if (is->step)
             stream_toggle_pause(is);
+
+        return 0;  // job complete
     }
  the_end:
     avcodec_flush_buffers(is->video_st->codec);
@@ -2272,6 +2359,7 @@ static int stream_component_open(VideoState *is, int stream_index)
         case AVMEDIA_TYPE_AUDIO   : is->last_audio_stream    = stream_index; if(audio_codec_name   ) codec= avcodec_find_decoder_by_name(   audio_codec_name); break;
         case AVMEDIA_TYPE_SUBTITLE: is->last_subtitle_stream = stream_index; if(subtitle_codec_name) codec= avcodec_find_decoder_by_name(subtitle_codec_name); break;
         case AVMEDIA_TYPE_VIDEO   : is->last_video_stream    = stream_index; if(video_codec_name   ) codec= avcodec_find_decoder_by_name(   video_codec_name); break;
+        default:;  // warning fix
     }
     if (!codec)
         return -1;
@@ -2380,7 +2468,7 @@ static int stream_component_open(VideoState *is, int stream_index)
         is->video_st = ic->streams[stream_index];
 
         packet_queue_start(&is->videoq);
-        is->video_tid = SDL_CreateThread(video_thread, is);
+        is->video_queue = dispatch_queue_create("video", DISPATCH_QUEUE_SERIAL);
         break;
     case AVMEDIA_TYPE_SUBTITLE:
         is->subtitle_stream = stream_index;
@@ -2427,6 +2515,7 @@ static void stream_component_close(VideoState *is, int stream_index)
         break;
     case AVMEDIA_TYPE_VIDEO:
         packet_queue_abort(&is->videoq);
+        dispatch_async(is->video_queue, ^{ video_stage(is); });  // one more run for cleanup
 
         /* note: we also signal this mutex to make sure we deblock the
            video thread in all cases */
@@ -2434,7 +2523,8 @@ static void stream_component_close(VideoState *is, int stream_index)
         SDL_CondSignal(is->pictq_cond);
         SDL_UnlockMutex(is->pictq_mutex);
 
-        SDL_WaitThread(is->video_tid, NULL);
+        dispatch_sync(is->video_queue, ^{});
+        dispatch_release(is->video_queue);
 
         packet_queue_flush(&is->videoq);
         break;
@@ -2484,15 +2574,22 @@ static int decode_interrupt_cb(void *ctx)
 }
 
 /* this thread gets the stream from the disk or the network */
-static int read_thread(void *arg)
+static int read_stage(void *arg)  // called input stage in the thesis
 {
     VideoState *is = arg;
-    AVFormatContext *ic = NULL;
-    int err, i, ret;
-    int st_index[AVMEDIA_TYPE_NB];
+    static AVFormatContext *ic;
+    __block int ret = 0;
+    static int st_index[AVMEDIA_TYPE_NB];
     AVPacket pkt1, *pkt = &pkt1;
-    int eof = 0;
+    static int eof = 0;
     int pkt_in_play_range = 0;
+    static nalu_read_t *nalu;
+
+static dispatch_once_t predicate;
+dispatch_once(&predicate, ^{
+    nalu = nalu_read_alloc();
+
+    int err, i;
     AVDictionaryEntry *t;
     AVDictionary **opts;
     int orig_nb_streams;
@@ -2509,12 +2606,12 @@ static int read_thread(void *arg)
     if (err < 0) {
         print_error(is->filename, err);
         ret = -1;
-        goto fail;
+        return;
     }
     if ((t = av_dict_get(format_opts, "", NULL, AV_DICT_IGNORE_SUFFIX))) {
         av_log(NULL, AV_LOG_ERROR, "Option %s not found.\n", t->key);
         ret = AVERROR_OPTION_NOT_FOUND;
-        goto fail;
+        return;
     }
     is->ic = ic;
 
@@ -2528,7 +2625,7 @@ static int read_thread(void *arg)
     if (err < 0) {
         fprintf(stderr, "%s: could not find codec parameters\n", is->filename);
         ret = -1;
-        goto fail;
+        return;
     }
     for (i = 0; i < orig_nb_streams; i++)
         av_dict_free(&opts[i]);
@@ -2586,11 +2683,10 @@ static int read_thread(void *arg)
         stream_component_open(is, st_index[AVMEDIA_TYPE_AUDIO]);
     }
 
-    ret = -1;
     if (st_index[AVMEDIA_TYPE_VIDEO] >= 0) {
-        ret = stream_component_open(is, st_index[AVMEDIA_TYPE_VIDEO]);
+        stream_component_open(is, st_index[AVMEDIA_TYPE_VIDEO]);
     }
-    is->refresh_tid = SDL_CreateThread(refresh_thread, is);
+    is->refresh_queue = dispatch_queue_create("refresh", DISPATCH_QUEUE_SERIAL);
     if (is->show_mode == SHOW_MODE_NONE)
         is->show_mode = ret >= 0 ? SHOW_MODE_VIDEO : SHOW_MODE_RDFT;
 
@@ -2601,8 +2697,22 @@ static int read_thread(void *arg)
     if (is->video_stream < 0 && is->audio_stream < 0) {
         fprintf(stderr, "%s: could not open codecs\n", is->filename);
         ret = -1;
-        goto fail;
+        return;
     }
+});
+    if (ret != 0)
+        goto fail;
+    if (!nalu)
+        return 0;  // the cleanup code already ran before
+
+    atlas_job_t job = {
+#ifdef DEADLINE_FAR
+        .deadline = is->frame_timer + is->videoq.nb_packets * av_q2d(is->video_st->codec->time_base)
+#else
+        .deadline = is->frame_timer + av_q2d(is->video_st->codec->time_base)
+#endif
+    };
+    dispatch_async_atlas(is->read_queue, job, ^{ read_stage(is); });
 
     for (;;) {
         if (is->abort_request)
@@ -2668,6 +2778,7 @@ static int read_thread(void *arg)
                 pkt->size = 0;
                 pkt->stream_index = is->video_stream;
                 packet_queue_put(&is->videoq, pkt);
+                dispatch_async(is->video_queue, ^{ video_stage(is); });
             }
             if (is->audio_stream >= 0 &&
                 is->audio_st->codec->codec->capabilities & CODEC_CAP_DELAY) {
@@ -2682,6 +2793,9 @@ static int read_thread(void *arg)
                 if (loop != 1 && (!loop || --loop)) {
                     stream_seek(is, start_time != AV_NOPTS_VALUE ? start_time : 0, 0, 0);
                 } else if (autoexit) {
+                    // wait until all frames have been displayed
+                    while (is->videoq.nb_packets + is->pictq_size > 0)
+                        SDL_Delay(100);
                     ret = AVERROR_EOF;
                     goto fail;
                 }
@@ -2696,7 +2810,7 @@ static int read_thread(void *arg)
             if (ic->pb && ic->pb->error)
                 break;
             SDL_Delay(100); /* wait for user event */
-            continue;
+            return 0;  // job complete
         }
         /* check if packet is in play range specified by user, then queue, otherwise discard */
         pkt_in_play_range = duration == AV_NOPTS_VALUE ||
@@ -2707,12 +2821,70 @@ static int read_thread(void *arg)
         if (pkt->stream_index == is->audio_stream && pkt_in_play_range) {
             packet_queue_put(&is->audioq, pkt);
         } else if (pkt->stream_index == is->video_stream && pkt_in_play_range) {
+            /* extract metadata from custom NALU and submit job */
+            double metrics[METRICS_COUNT] = { 0.0 };
+            const uint8_t *metadata;
+
+            /* the metadata NALU is at the end */
+            for (metadata = pkt->data + pkt->size; metadata >= pkt->data + 4; metadata--)
+                if (metadata[-4] == 0 && metadata[-3] == 0 && metadata[-2] == 1 && metadata[-1] == NAL_METADATA)
+                    break;
+
+            if (metadata >= pkt->data + 4) {
+#if defined(METRICS_FULL)
+                uint_fast16_t mb_width, mb_height;
+                uint_fast8_t slice_count;
+                uint_fast8_t slice_type;
+
+                nalu_read_start(nalu, metadata);
+                mb_width = nalu_read_unsigned(nalu);
+                mb_height = nalu_read_unsigned(nalu);
+                metrics[0] = mb_width * mb_height;
+                slice_count = nalu_read_unsigned(nalu);
+                for (slice_count = 1; slice_count; slice_count--) {  // dirty multi-slice support: only one slice with aggregate metrics
+                    slice_type = nalu_read_unsigned(nalu);
+                    assert(METRICS_COUNT == 13);
+                    for (size_t i = 1; i < 13; i++)
+                        metrics[i] += nalu_read_unsigned(nalu);
+                }
+#elif defined(METRICS_REDUCED)
+                uint_fast16_t mb_width, mb_height;
+                uint_fast8_t slice_count;
+                uint_fast8_t slice_type;
+
+                nalu_read_start(nalu, metadata);
+                mb_width = nalu_read_unsigned(nalu);
+                mb_height = nalu_read_unsigned(nalu);
+                slice_count = nalu_read_unsigned(nalu);
+                slice_type = nalu_read_unsigned(nalu);
+                metrics[0] = mb_width * mb_height;
+                metrics[1] = pkt->size;
+                metrics[2] = (slice_type == 0);
+                metrics[3] = (slice_type == 1);
+                metrics[4] = (slice_type == 2);
+#endif
+            }
+
             packet_queue_put(&is->videoq, pkt);
+
+            atlas_job_t job = {
+#ifdef DEADLINE_FAR
+                .deadline = is->frame_timer + (is->videoq.nb_packets + is->pictq_size) * av_q2d(is->video_st->codec->time_base),
+#else
+                .deadline = is->frame_timer + is->videoq.nb_packets * av_q2d(is->video_st->codec->time_base),
+#endif
+                .metrics_count = METRICS_COUNT,
+                .metrics = metrics
+            };
+            dispatch_async_atlas(is->video_queue, job, ^{ video_stage(is); });
+
         } else if (pkt->stream_index == is->subtitle_stream && pkt_in_play_range) {
             packet_queue_put(&is->subtitleq, pkt);
         } else {
             av_free_packet(pkt);
         }
+
+        return 0;  // job complete
     }
     /* wait until the end */
     while (!is->abort_request) {
@@ -2731,6 +2903,8 @@ static int read_thread(void *arg)
     if (is->ic) {
         avformat_close_input(&is->ic);
     }
+    nalu_read_free(nalu);
+    nalu = NULL;
 
     if (ret != 0) {
         SDL_Event event;
@@ -2766,11 +2940,15 @@ static VideoState *stream_open(const char *filename, AVInputFormat *iformat)
     packet_queue_init(&is->subtitleq);
 
     is->av_sync_type = av_sync_type;
-    is->read_tid     = SDL_CreateThread(read_thread, is);
-    if (!is->read_tid) {
+    is->main_thread = gettid();
+    is->frame_timer = atlas_now();  // deadlines are based on frame_timer, set early
+    is->read_queue = dispatch_queue_create("read", DISPATCH_QUEUE_SERIAL);
+    if (!is->read_queue) {
         av_free(is);
         return NULL;
     }
+    atlas_pin_cpu(0);
+    dispatch_async(is->read_queue, ^{ read_stage(is); });
     return is;
 }
 
@@ -3007,6 +3185,13 @@ static void event_loop(VideoState *cur_stream)
             alloc_picture(event.user.data1);
             break;
         case FF_REFRESH_EVENT:
+            if (event.user.code) {
+                static int train_job = 0;
+                if (train_job)
+                    atlas_job_train(video_refresh);
+                atlas_job_next(video_refresh);
+                train_job = 1;
+            }
             video_refresh(event.user.data1);
             cur_stream->refresh = 0;
             break;
@@ -3282,7 +3467,7 @@ int main(int argc, char **argv)
     }
 
     av_init_packet(&flush_pkt);
-    flush_pkt.data = (char *)(intptr_t)"FLUSH";
+    flush_pkt.data = (uint8_t *)(intptr_t)"FLUSH";  // warning fix
 
     is = stream_open(input_filename, file_iformat);
     if (!is) {
diff --git a/libavcodec/avcodec.h b/libavcodec/avcodec.h
index 96ca401..0fefe45 100644
--- a/libavcodec/avcodec.h
+++ b/libavcodec/avcodec.h
@@ -2914,6 +2914,91 @@ typedef struct AVCodecContext {
     int64_t pts_correction_num_faulty_dts; /// Number of incorrect DTS values so far
     int64_t pts_correction_last_pts;       /// PTS of the last frame
     int64_t pts_correction_last_dts;       /// DTS of the last frame
+
+    /* callback for external slice processing */
+    void (*process_slice)(void *);
+    /* callback for metadata processing */
+    void (*process_metadata)(const uint8_t *);
+    /* callback for external macroblock processing */
+    void (*process_mb)(void *);
+
+    /* NALU type number for our custom metadata NALUs */
+#define NAL_METADATA   0x1F
+    /* pseudo slices */
+#define PSEUDO_SLICE_FRAME_START  -1
+#define PSEUDO_SLICE_FRAME_END    -2
+
+    /* the metrics for the decoding time estimation */
+    /* toggle metrics extraction */
+#define FFMPEG_METRICS 1
+#if FFMPEG_METRICS
+#   define FFMPEG_METRICS_EXTRACT(x) x
+#else
+#   define FFMPEG_METRICS_EXTRACT(x)
+#endif
+    struct {
+        int32_t  type;
+        uint32_t bits_cabac;
+        uint32_t bits_cavlc;
+        uint32_t intra_4x4;
+        uint32_t intra_8x8;
+        uint32_t intra_16x16;
+        uint32_t inter_4x4;
+        uint32_t inter_8x8;
+        uint32_t inter_16x16;
+        uint32_t idct_pcm;
+        uint32_t idct_4x4;
+        uint32_t idct_8x8;
+        uint32_t deblock_edges;
+    } metrics;
+
+    /* time measurements */
+    /* toggle time measurement */
+#define FFMPEG_TIME 0
+#if FFMPEG_TIME
+#   define FFMPEG_TIME_START(context,slot) context->timing.slot -= read_time()
+#   define FFMPEG_TIME_STOP(context,slot) context->timing.slot += read_time()
+#else
+#   define FFMPEG_TIME_START(context,slot)
+#   define FFMPEG_TIME_STOP(context,slot)
+#endif
+    struct {
+        uint64_t decompression;     /* decode_mb_cabac and _cavlc, includes iscan and iquant */
+        uint64_t spatial;           /* pred4x4, pred8x8, pred8x8l, pred16x16 */
+        uint64_t temporal;          /* hl_motion */
+        uint64_t transform;         /* pcm, idct and merge */
+        uint64_t post;              /* xchg_mb_border, filter_mb */
+        uint64_t total;
+    } timing;
+
+    /* frame structure */
+    struct {
+        int flag_idr;
+        AVFrame *current;
+        AVFrame *display;
+        uint32_t mb_width;
+        uint32_t mb_height;
+    } frame;
+
+    /* slice structure; does not support FMO */
+    struct {
+        int flag_last;
+        int start_index;  /* macroblock numbers, start inclusive, end exclusive */
+        int end_index;
+        int skip;         /* in-parameter to skip the next slice */
+        int conceal;      /* in-parameter to activate FFmpeg's error concealment */
+    } slice;
+
+    /* reference structure */
+    struct {
+        int long_count;
+        int short_count;
+        AVFrame *long_list[32];
+        AVFrame *short_list[32];
+        int count[2];
+        AVFrame *list[2][32];
+    } reference;
+
 } AVCodecContext;
 
 /**
diff --git a/libavcodec/h264.c b/libavcodec/h264.c
index 22f5527..fa2b543 100644
--- a/libavcodec/h264.c
+++ b/libavcodec/h264.c
@@ -70,6 +70,17 @@ static const enum PixelFormat hwaccel_pixfmt_list_h264_jpeg_420[] = {
     PIX_FMT_NONE
 };
 
+FFMPEG_METRICS_EXTRACT(static int *inter_type);
+static const int qpel_luma_cost[] = {
+    1, 10,  6, 10,
+    10,  6,  7,  6,
+    6,  7,  6,  7,
+    10,  6,  7,  6
+};
+static const int qpel_chroma_cost[] = {
+    2, 4, 8
+};
+
 /**
  * Check if the top & left blocks are available if needed and
  * change the dc mode so it only uses the available blocks.
@@ -497,6 +508,8 @@ static av_always_inline void mc_dir_part(H264Context *h, Picture *pic,
         emu   = 1;
     }
 
+    FFMPEG_METRICS_EXTRACT(*inter_type += (1 + !square) * (qpel_luma_cost[luma_xy] + qpel_chroma_cost[!!(mx&7)+!!(my&7)]));
+
     qpix_op[luma_xy](dest_y, src_y, h->mb_linesize); // FIXME try variable height perhaps?
     if (!square)
         qpix_op[luma_xy](dest_y + delta, src_y + delta, h->mb_linesize);
@@ -796,12 +809,14 @@ static av_always_inline void hl_motion(H264Context *h, uint8_t *dest_y,
     prefetch_motion(h, 0, pixel_shift, chroma_idc);
 
     if (IS_16X16(mb_type)) {
+        FFMPEG_METRICS_EXTRACT(inter_type = &s->avctx->metrics.inter_16x16);
         mc_part(h, 0, 1, 16, 0, dest_y, dest_cb, dest_cr, 0, 0,
                 qpix_put[0], chroma_put[0], qpix_avg[0], chroma_avg[0],
                 weight_op, weight_avg,
                 IS_DIR(mb_type, 0, 0), IS_DIR(mb_type, 0, 1),
                 pixel_shift, chroma_idc);
     } else if (IS_16X8(mb_type)) {
+        FFMPEG_METRICS_EXTRACT(inter_type = &s->avctx->metrics.inter_8x8);
         mc_part(h, 0, 0, 8, 8 << pixel_shift, dest_y, dest_cb, dest_cr, 0, 0,
                 qpix_put[1], chroma_put[0], qpix_avg[1], chroma_avg[0],
                 weight_op, weight_avg,
@@ -813,6 +828,7 @@ static av_always_inline void hl_motion(H264Context *h, uint8_t *dest_y,
                 IS_DIR(mb_type, 1, 0), IS_DIR(mb_type, 1, 1),
                 pixel_shift, chroma_idc);
     } else if (IS_8X16(mb_type)) {
+        FFMPEG_METRICS_EXTRACT(inter_type = &s->avctx->metrics.inter_8x8);
         mc_part(h, 0, 0, 16, 8 * h->mb_linesize, dest_y, dest_cb, dest_cr, 0, 0,
                 qpix_put[1], chroma_put[1], qpix_avg[1], chroma_avg[1],
                 &weight_op[1], &weight_avg[1],
@@ -835,6 +851,7 @@ static av_always_inline void hl_motion(H264Context *h, uint8_t *dest_y,
             int y_offset = (i & 2) << 1;
 
             if (IS_SUB_8X8(sub_mb_type)) {
+                FFMPEG_METRICS_EXTRACT(inter_type = &s->avctx->metrics.inter_8x8);
                 mc_part(h, n, 1, 8, 0, dest_y, dest_cb, dest_cr,
                         x_offset, y_offset,
                         qpix_put[1], chroma_put[1], qpix_avg[1], chroma_avg[1],
@@ -842,6 +859,7 @@ static av_always_inline void hl_motion(H264Context *h, uint8_t *dest_y,
                         IS_DIR(sub_mb_type, 0, 0), IS_DIR(sub_mb_type, 0, 1),
                         pixel_shift, chroma_idc);
             } else if (IS_SUB_8X4(sub_mb_type)) {
+                FFMPEG_METRICS_EXTRACT(inter_type = &s->avctx->metrics.inter_4x4);
                 mc_part(h, n, 0, 4, 4 << pixel_shift, dest_y, dest_cb, dest_cr,
                         x_offset, y_offset,
                         qpix_put[2], chroma_put[1], qpix_avg[2], chroma_avg[1],
@@ -855,6 +873,7 @@ static av_always_inline void hl_motion(H264Context *h, uint8_t *dest_y,
                         IS_DIR(sub_mb_type, 0, 0), IS_DIR(sub_mb_type, 0, 1),
                         pixel_shift, chroma_idc);
             } else if (IS_SUB_4X8(sub_mb_type)) {
+                FFMPEG_METRICS_EXTRACT(inter_type = &s->avctx->metrics.inter_4x4);
                 mc_part(h, n, 0, 8, 4 * h->mb_linesize,
                         dest_y, dest_cb, dest_cr, x_offset, y_offset,
                         qpix_put[2], chroma_put[2], qpix_avg[2], chroma_avg[2],
@@ -870,6 +889,7 @@ static av_always_inline void hl_motion(H264Context *h, uint8_t *dest_y,
             } else {
                 int j;
                 assert(IS_SUB_4X4(sub_mb_type));
+                FFMPEG_METRICS_EXTRACT(inter_type = &s->avctx->metrics.inter_4x4);
                 for (j = 0; j < 4; j++) {
                     int sub_x_offset = x_offset + 2 * (j & 1);
                     int sub_y_offset = y_offset + (j & 2);
@@ -1901,20 +1921,28 @@ static av_always_inline void hl_decode_mb_predict_luma(H264Context *h,
                     idct_add    = h->h264dsp.h264_idct8_add;
                 }
                 for (i = 0; i < 16; i += 4) {
+                    FFMPEG_METRICS_EXTRACT(s->avctx->metrics.intra_8x8++);
                     uint8_t *const ptr = dest_y + block_offset[i];
                     const int dir      = h->intra4x4_pred_mode_cache[scan8[i]];
                     if (transform_bypass && h->sps.profile_idc == 244 && dir <= 1) {
+                        FFMPEG_TIME_START(s->avctx, spatial);
                         h->hpc.pred8x8l_add[dir](ptr, h->mb + (i * 16 + p * 256 << pixel_shift), linesize);
+                        FFMPEG_TIME_STOP(s->avctx, spatial);
                     } else {
                         const int nnz = h->non_zero_count_cache[scan8[i + p * 16]];
+                        FFMPEG_TIME_START(s->avctx, spatial);
                         h->hpc.pred8x8l[dir](ptr, (h->topleft_samples_available << i) & 0x8000,
                                              (h->topright_samples_available << i) & 0x4000, linesize);
+                        FFMPEG_TIME_STOP(s->avctx, spatial);
+                        FFMPEG_TIME_START(s->avctx, transform);
                         if (nnz) {
+                            FFMPEG_METRICS_EXTRACT(transform_bypass ? 0 : s->avctx->metrics.idct_8x8++);
                             if (nnz == 1 && dctcoef_get(h->mb, pixel_shift, i * 16 + p * 256))
                                 idct_dc_add(ptr, h->mb + (i * 16 + p * 256 << pixel_shift), linesize);
                             else
                                 idct_add(ptr, h->mb + (i * 16 + p * 256 << pixel_shift), linesize);
                         }
+                        FFMPEG_TIME_STOP(s->avctx, transform);
                     }
                 }
             } else {
@@ -1926,11 +1954,14 @@ static av_always_inline void hl_decode_mb_predict_luma(H264Context *h,
                     idct_add    = h->h264dsp.h264_idct_add;
                 }
                 for (i = 0; i < 16; i++) {
+                    FFMPEG_METRICS_EXTRACT(s->avctx->metrics.intra_4x4++);
                     uint8_t *const ptr = dest_y + block_offset[i];
                     const int dir      = h->intra4x4_pred_mode_cache[scan8[i]];
 
                     if (transform_bypass && h->sps.profile_idc == 244 && dir <= 1) {
+                        FFMPEG_TIME_START(s->avctx, spatial);
                         h->hpc.pred4x4_add[dir](ptr, h->mb + (i * 16 + p * 256 << pixel_shift), linesize);
+                        FFMPEG_TIME_STOP(s->avctx, spatial);
                     } else {
                         uint8_t *topright;
                         int nnz, tr;
@@ -1951,10 +1982,14 @@ static av_always_inline void hl_decode_mb_predict_luma(H264Context *h,
                         } else
                             topright = NULL;
 
+                        FFMPEG_TIME_START(s->avctx, spatial);
                         h->hpc.pred4x4[dir](ptr, topright, linesize);
+                        FFMPEG_TIME_STOP(s->avctx, spatial);
+                        FFMPEG_TIME_START(s->avctx, transform);
                         nnz = h->non_zero_count_cache[scan8[i + p * 16]];
                         if (nnz) {
                             if (is_h264) {
+                                FFMPEG_METRICS_EXTRACT(transform_bypass ? 0 : s->avctx->metrics.idct_4x4++);
                                 if (nnz == 1 && dctcoef_get(h->mb, pixel_shift, i * 16 + p * 256))
                                     idct_dc_add(ptr, h->mb + (i * 16 + p * 256 << pixel_shift), linesize);
                                 else
@@ -1962,12 +1997,17 @@ static av_always_inline void hl_decode_mb_predict_luma(H264Context *h,
                             } else if (CONFIG_SVQ3_DECODER)
                                 ff_svq3_add_idct_c(ptr, h->mb + i * 16 + p * 256, linesize, qscale, 0);
                         }
+                        FFMPEG_TIME_STOP(s->avctx, transform);
                     }
                 }
             }
         }
     } else {
+        FFMPEG_METRICS_EXTRACT(s->avctx->metrics.intra_16x16++);
+        FFMPEG_TIME_START(s->avctx, spatial);
         h->hpc.pred16x16[h->intra16x16_pred_mode](dest_y, linesize);
+        FFMPEG_TIME_STOP(s->avctx, spatial);
+        FFMPEG_TIME_START(s->avctx, transform);
         if (is_h264) {
             if (h->non_zero_count_cache[scan8[LUMA_DC_BLOCK_INDEX + p]]) {
                 if (!transform_bypass)
@@ -1990,6 +2030,7 @@ static av_always_inline void hl_decode_mb_predict_luma(H264Context *h,
         } else if (CONFIG_SVQ3_DECODER)
             ff_svq3_luma_dc_dequant_idct_c(h->mb + p * 256,
                                            h->mb_luma_dc[p], qscale);
+        FFMPEG_TIME_STOP(s->avctx, transform);
     }
 }
 
@@ -2012,34 +2053,46 @@ static av_always_inline void hl_decode_mb_idct_luma(H264Context *h, int mb_type,
                     if (h->sps.profile_idc == 244 &&
                         (h->intra16x16_pred_mode == VERT_PRED8x8 ||
                          h->intra16x16_pred_mode == HOR_PRED8x8)) {
+                        FFMPEG_METRICS_EXTRACT(s->avctx->metrics.intra_16x16++);
+                        FFMPEG_TIME_START(s->avctx, spatial);
                         h->hpc.pred16x16_add[h->intra16x16_pred_mode](dest_y, block_offset,
                                                                       h->mb + (p * 256 << pixel_shift),
                                                                       linesize);
+                        FFMPEG_TIME_STOP(s->avctx, spatial);
                     } else {
+                        FFMPEG_TIME_START(s->avctx, transform);
                         for (i = 0; i < 16; i++)
                             if (h->non_zero_count_cache[scan8[i + p * 16]] ||
                                 dctcoef_get(h->mb, pixel_shift, i * 16 + p * 256))
                                 s->dsp.add_pixels4(dest_y + block_offset[i],
                                                    h->mb + (i * 16 + p * 256 << pixel_shift),
                                                    linesize);
+                        FFMPEG_TIME_STOP(s->avctx, transform);
                     }
                 } else {
+                    FFMPEG_METRICS_EXTRACT(s->avctx->metrics.idct_4x4 += 16);
+                    FFMPEG_TIME_START(s->avctx, transform);
                     h->h264dsp.h264_idct_add16intra(dest_y, block_offset,
                                                     h->mb + (p * 256 << pixel_shift),
                                                     linesize,
                                                     h->non_zero_count_cache + p * 5 * 8);
+                    FFMPEG_TIME_STOP(s->avctx, transform);
                 }
             } else if (h->cbp & 15) {
                 if (transform_bypass) {
                     const int di = IS_8x8DCT(mb_type) ? 4 : 1;
                     idct_add = IS_8x8DCT(mb_type) ? s->dsp.add_pixels8
                                                   : s->dsp.add_pixels4;
+                    FFMPEG_TIME_START(s->avctx, transform);
                     for (i = 0; i < 16; i += di)
                         if (h->non_zero_count_cache[scan8[i + p * 16]])
                             idct_add(dest_y + block_offset[i],
                                      h->mb + (i * 16 + p * 256 << pixel_shift),
                                      linesize);
+                    FFMPEG_TIME_STOP(s->avctx, transform);
                 } else {
+                    FFMPEG_METRICS_EXTRACT(IS_8x8DCT(mb_type) ? (s->avctx->metrics.idct_8x8 += 4) : (s->avctx->metrics.idct_4x4 += 16));
+                    FFMPEG_TIME_START(s->avctx, transform);
                     if (IS_8x8DCT(mb_type))
                         h->h264dsp.h264_idct8_add4(dest_y, block_offset,
                                                    h->mb + (p * 256 << pixel_shift),
@@ -2050,6 +2103,7 @@ static av_always_inline void hl_decode_mb_idct_luma(H264Context *h, int mb_type,
                                                    h->mb + (p * 256 << pixel_shift),
                                                    linesize,
                                                    h->non_zero_count_cache + p * 5 * 8);
+                    FFMPEG_TIME_STOP(s->avctx, transform);
                 }
             }
         } else if (CONFIG_SVQ3_DECODER) {
@@ -2126,6 +2180,8 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
     }
 
     if (!simple && IS_INTRA_PCM(mb_type)) {
+        FFMPEG_METRICS_EXTRACT(s->avctx->metrics.idct_pcm++);
+        FFMPEG_TIME_START(s->avctx, transform);
         const int bit_depth = h->sps.bit_depth_luma;
         if (pixel_shift) {
             int j;
@@ -2179,16 +2235,21 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
                 }
             }
         }
+        FFMPEG_TIME_STOP(s->avctx, transform);
     } else {
         if (IS_INTRA(mb_type)) {
+            FFMPEG_TIME_START(s->avctx, post);
             if (h->deblocking_filter)
                 xchg_mb_border(h, dest_y, dest_cb, dest_cr, linesize,
                                uvlinesize, 1, 0, simple, pixel_shift);
+            FFMPEG_TIME_STOP(s->avctx, post);
 
             if (simple || !CONFIG_GRAY || !(s->flags & CODEC_FLAG_GRAY)) {
                 if (CHROMA) {
+                    FFMPEG_TIME_START(s->avctx, spatial);
                     h->hpc.pred8x8[h->chroma_pred_mode](dest_cb, uvlinesize);
                     h->hpc.pred8x8[h->chroma_pred_mode](dest_cr, uvlinesize);
+                    FFMPEG_TIME_STOP(s->avctx, spatial);
                 }
             }
 
@@ -2196,10 +2257,13 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
                                       transform_bypass, pixel_shift,
                                       block_offset, linesize, dest_y, 0);
 
+            FFMPEG_TIME_START(s->avctx, post);
             if (h->deblocking_filter)
                 xchg_mb_border(h, dest_y, dest_cb, dest_cr, linesize,
                                uvlinesize, 0, 0, simple, pixel_shift);
+            FFMPEG_TIME_STOP(s->avctx, post);
         } else if (is_h264) {
+            FFMPEG_TIME_START(s->avctx, temporal);
             if (chroma422) {
                 hl_motion_422(h, dest_y, dest_cb, dest_cr,
                               s->me.qpel_put, s->dsp.put_h264_chroma_pixels_tab,
@@ -2215,6 +2279,7 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
                               h->h264dsp.biweight_h264_pixels_tab,
                               pixel_shift);
             }
+            FFMPEG_TIME_STOP(s->avctx, temporal);
         }
 
         hl_decode_mb_idct_luma(h, mb_type, is_h264, simple, transform_bypass,
@@ -2227,6 +2292,7 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
                 if (IS_INTRA(mb_type) && h->sps.profile_idc == 244 &&
                     (h->chroma_pred_mode == VERT_PRED8x8 ||
                      h->chroma_pred_mode == HOR_PRED8x8)) {
+                    FFMPEG_TIME_START(s->avctx, spatial);
                     h->hpc.pred8x8_add[h->chroma_pred_mode](dest[0],
                                                             block_offset + 16,
                                                             h->mb + (16 * 16 * 1 << pixel_shift),
@@ -2235,8 +2301,10 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
                                                             block_offset + 32,
                                                             h->mb + (16 * 16 * 2 << pixel_shift),
                                                             uvlinesize);
+                    FFMPEG_TIME_STOP(s->avctx, spatial);
                 } else {
                     idct_add = s->dsp.add_pixels4;
+                    FFMPEG_TIME_START(s->avctx, transform);
                     for (j = 1; j < 3; j++) {
                         for (i = j * 16; i < j * 16 + 4; i++)
                             if (h->non_zero_count_cache[scan8[i]] ||
@@ -2253,6 +2321,7 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
                                              uvlinesize);
                         }
                     }
+                    FFMPEG_TIME_STOP(s->avctx, transform);
                 }
             } else {
                 if (is_h264) {
@@ -2264,6 +2333,8 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
                         qp[0] = h->chroma_qp[0];
                         qp[1] = h->chroma_qp[1];
                     }
+                    FFMPEG_METRICS_EXTRACT(s->avctx->metrics.idct_4x4 += 8);
+                    FFMPEG_TIME_START(s->avctx, transform);
                     if (h->non_zero_count_cache[scan8[CHROMA_DC_BLOCK_INDEX + 0]])
                         h->h264dsp.h264_chroma_dc_dequant_idct(h->mb + (16 * 16 * 1 << pixel_shift),
                                                                h->dequant4_coeff[IS_INTRA(mb_type) ? 1 : 4][qp[0]][0]);
@@ -2273,6 +2344,7 @@ static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple,
                     h->h264dsp.h264_idct_add8(dest, block_offset,
                                               h->mb, uvlinesize,
                                               h->non_zero_count_cache);
+                    FFMPEG_TIME_STOP(s->avctx, transform);
                 } else if (CONFIG_SVQ3_DECODER) {
                     h->h264dsp.h264_chroma_dc_dequant_idct(h->mb + 16 * 16 * 1,
                                                            h->dequant4_coeff[IS_INTRA(mb_type) ? 1 : 4][h->chroma_qp[0]][0]);
@@ -2351,6 +2423,8 @@ static av_always_inline void hl_decode_mb_444_internal(H264Context *h,
     }
 
     if (!simple && IS_INTRA_PCM(mb_type)) {
+        FFMPEG_METRICS_EXTRACT(s->avctx->metrics.idct_pcm++);
+        FFMPEG_TIME_START(s->avctx, transform);
         if (pixel_shift) {
             const int bit_depth = h->sps.bit_depth_luma;
             GetBitContext gb;
@@ -2368,26 +2442,33 @@ static av_always_inline void hl_decode_mb_444_internal(H264Context *h,
                     memcpy(dest[p] + i * linesize,
                            (uint8_t *)h->mb + p * 256 + i * 16, 16);
         }
+        FFMPEG_TIME_STOP(s->avctx, transform);
     } else {
         if (IS_INTRA(mb_type)) {
+            FFMPEG_TIME_START(s->avctx, post);
             if (h->deblocking_filter)
                 xchg_mb_border(h, dest[0], dest[1], dest[2], linesize,
                                linesize, 1, 1, simple, pixel_shift);
+            FFMPEG_TIME_STOP(s->avctx, post);
 
             for (p = 0; p < plane_count; p++)
                 hl_decode_mb_predict_luma(h, mb_type, 1, simple,
                                           transform_bypass, pixel_shift,
                                           block_offset, linesize, dest[p], p);
 
+            FFMPEG_TIME_START(s->avctx, post);
             if (h->deblocking_filter)
                 xchg_mb_border(h, dest[0], dest[1], dest[2], linesize,
                                linesize, 0, 1, simple, pixel_shift);
+            FFMPEG_TIME_STOP(s->avctx, post);
         } else {
+            FFMPEG_TIME_START(s->avctx, temporal);
             hl_motion(h, dest[0], dest[1], dest[2],
                       s->me.qpel_put, s->dsp.put_h264_chroma_pixels_tab,
                       s->me.qpel_avg, s->dsp.avg_h264_chroma_pixels_tab,
                       h->h264dsp.weight_h264_pixels_tab,
                       h->h264dsp.biweight_h264_pixels_tab, pixel_shift, 3);
+            FFMPEG_TIME_STOP(s->avctx, temporal);
         }
 
         for (p = 0; p < plane_count; p++)
@@ -3871,6 +3952,7 @@ static void loop_filter(H264Context *h, int start_x, int end_x)
     const int pixel_shift    = h->pixel_shift;
     const int block_h        = 16 >> s->chroma_y_shift;
 
+    FFMPEG_TIME_START(s->avctx, post);
     if (h->deblocking_filter) {
         for (mb_x = start_x; mb_x < end_x; mb_x++)
             for (mb_y = end_mb_y - FRAME_MBAFF; mb_y <= end_mb_y; mb_y++) {
@@ -3924,6 +4006,7 @@ static void loop_filter(H264Context *h, int start_x, int end_x)
                 }
             }
     }
+    FFMPEG_TIME_STOP(s->avctx, post);
     h->slice_type   = old_slice_type;
     s->mb_x         = end_x;
     s->mb_y         = end_mb_y - FRAME_MBAFF;
@@ -3984,6 +4067,48 @@ static int decode_slice(struct AVCodecContext *avctx, void *arg)
     const int part_mask     = s->partitioned_frame ? (ER_AC_END | ER_AC_ERROR)
                                                    : 0x7F;
     int lf_x_start = s->mb_x;
+    FFMPEG_METRICS_EXTRACT(unsigned bits_gone_by = 0);
+
+     /* new slice coming up, process previous one */
+    s->avctx->frame.flag_idr  = (h->nal_unit_type == NAL_IDR_SLICE);
+    s->avctx->frame.current   = (AVFrame *)&s->current_picture;
+    s->avctx->frame.mb_width  = s->mb_width;
+    s->avctx->frame.mb_height = s->mb_height;
+    s->avctx->slice.end_index = s->mb_x + s->mb_y * s->mb_width;
+    s->avctx->reference.long_count  = h->long_ref_count;
+    s->avctx->reference.short_count = h->short_ref_count;
+    memcpy(s->avctx->reference.long_list , h->long_ref , sizeof(h->long_ref ));
+    memcpy(s->avctx->reference.short_list, h->short_ref, sizeof(h->short_ref));
+    if (s->avctx->slice.skip && !s->avctx->slice.conceal)
+        // previous slice has been skipped, mark it done so that error resilience does not kick in
+        ff_er_add_slice(s,
+                        s->avctx->slice.start_index % s->mb_width,
+                        s->avctx->slice.start_index / s->mb_width,
+                        s->avctx->slice.end_index % s->mb_width - 1,
+                        s->avctx->slice.end_index / s->mb_width,
+                        ER_MB_END & 0x7F);
+    if (avctx->process_slice) {
+        emms_c();
+        avctx->process_slice(s->avctx);
+    }
+    /* prepare data for upcoming slice */
+    s->avctx->metrics.type = h->slice_type;
+    s->avctx->slice.start_index = s->mb_x + s->mb_y * s->mb_width;
+    s->avctx->reference.count[0] = h->ref_count[0];
+    s->avctx->reference.count[1] = h->ref_count[1];
+    {
+        int i;
+        for (i = 0; i < 32; i++) {
+            s->avctx->reference.list[0][i] = (AVFrame *)&h->ref_list[0][i];
+            s->avctx->reference.list[1][i] = (AVFrame *)&h->ref_list[1][i];
+        }
+    }
+    if (s->avctx->slice.skip) {
+        // do not decode this slice and skip the given amount of macroblocks
+        s->mb_x = (s->avctx->slice.start_index + s->avctx->slice.skip) % s->mb_width;
+        s->mb_y = (s->avctx->slice.start_index + s->avctx->slice.skip) / s->mb_width;
+        return 0;
+    }
 
     s->mb_skip_run = -1;
 
@@ -3996,16 +4121,20 @@ static int decode_slice(struct AVCodecContext *avctx, void *arg)
         align_get_bits(&s->gb);
 
         /* init cabac */
+        FFMPEG_TIME_START(s->avctx, decompression);
         ff_init_cabac_states(&h->cabac);
         ff_init_cabac_decoder(&h->cabac,
                               s->gb.buffer + get_bits_count(&s->gb) / 8,
                               (get_bits_left(&s->gb) + 7) / 8);
 
         ff_h264_init_cabac_states(h);
+        FFMPEG_TIME_STOP(s->avctx, decompression);
 
         for (;;) {
             // START_TIMER
+            FFMPEG_TIME_START(s->avctx, decompression);
             int ret = ff_h264_decode_mb_cabac(h);
+            FFMPEG_TIME_STOP(s->avctx, decompression);
             int eos;
             // STOP_TIMER("decode_mb_cabac")
 
@@ -4016,13 +4145,26 @@ static int decode_slice(struct AVCodecContext *avctx, void *arg)
             if (ret >= 0 && FRAME_MBAFF) {
                 s->mb_y++;
 
+                FFMPEG_TIME_START(s->avctx, decompression);
                 ret = ff_h264_decode_mb_cabac(h);
+                FFMPEG_TIME_STOP(s->avctx, decompression);
 
                 if (ret >= 0)
                     ff_h264_hl_decode_mb(h);
                 s->mb_y--;
             }
+            FFMPEG_TIME_START(s->avctx, decompression);
             eos = get_cabac_terminate(&h->cabac);
+            FFMPEG_TIME_STOP(s->avctx, decompression);
+
+            FFMPEG_METRICS_EXTRACT(s->avctx->metrics.bits_cabac -= bits_gone_by);
+            FFMPEG_METRICS_EXTRACT(bits_gone_by = (h->cabac.bytestream - h->cabac.bytestream_start) * 8);
+            FFMPEG_METRICS_EXTRACT(s->avctx->metrics.bits_cabac += bits_gone_by);
+
+            if(s->avctx->process_mb) {
+                emms_c();
+                s->avctx->process_mb(s->avctx);
+            }
 
             if ((s->workaround_bugs & FF_BUG_TRUNCATED) &&
                 h->cabac.bytestream > h->cabac.bytestream_end + 2) {
@@ -4068,7 +4210,9 @@ static int decode_slice(struct AVCodecContext *avctx, void *arg)
         }
     } else {
         for (;;) {
+            FFMPEG_TIME_START(s->avctx, decompression);
             int ret = ff_h264_decode_mb_cavlc(h);
+            FFMPEG_TIME_STOP(s->avctx, decompression);
 
             if (ret >= 0)
                 ff_h264_hl_decode_mb(h);
@@ -4076,13 +4220,24 @@ static int decode_slice(struct AVCodecContext *avctx, void *arg)
             // FIXME optimal? or let mb_decode decode 16x32 ?
             if (ret >= 0 && FRAME_MBAFF) {
                 s->mb_y++;
+                FFMPEG_TIME_START(s->avctx, decompression);
                 ret = ff_h264_decode_mb_cavlc(h);
+                FFMPEG_TIME_STOP(s->avctx, decompression);
 
                 if (ret >= 0)
                     ff_h264_hl_decode_mb(h);
                 s->mb_y--;
             }
 
+            FFMPEG_METRICS_EXTRACT(s->avctx->metrics.bits_cavlc -= bits_gone_by);
+            FFMPEG_METRICS_EXTRACT(bits_gone_by = get_bits_count(&s->gb));
+            FFMPEG_METRICS_EXTRACT(s->avctx->metrics.bits_cavlc += bits_gone_by);
+
+            if(s->avctx->process_mb) {
+                emms_c();
+                s->avctx->process_mb(s->avctx);
+            }
+
             if (ret < 0) {
                 av_log(h->s.avctx, AV_LOG_ERROR,
                        "error while decoding MB %d %d\n", s->mb_x, s->mb_y);
@@ -4450,6 +4605,12 @@ again:
             case NAL_SPS_EXT:
             case NAL_AUXILIARY_SLICE:
                 break;
+            case NAL_METADATA:
+                if (s->avctx->process_metadata) {
+                    emms_c();
+                    s->avctx->process_metadata(ptr);
+                }
+            break;
             default:
                 av_log(avctx, AV_LOG_DEBUG, "Unknown NAL code: %d (%d bits)\n",
                        hx->nal_unit_type, bit_length);
@@ -4543,6 +4704,13 @@ static int decode_frame(AVCodecContext *avctx, void *data,
             *pict      = out->f;
         }
 
+        avctx->metrics.type = PSEUDO_SLICE_FRAME_END;
+        avctx->frame.display = *data_size ? pict : NULL;
+        if (avctx->process_slice) {
+            emms_c();
+            avctx->process_slice(avctx);
+        }
+
         return buf_index;
     }
     if(h->is_avc && buf_size >= 9 && buf[0]==1 && buf[2]==0 && (buf[4]&0xFC)==0xFC && (buf[5]&0x1F) && buf[8]==0x67){
@@ -4567,11 +4735,29 @@ static int decode_frame(AVCodecContext *avctx, void *data,
         return ff_h264_decode_extradata(h, buf, buf_size);
     }
 not_extra:
+    avctx->metrics.type = PSEUDO_SLICE_FRAME_START;
 
     buf_index = decode_nal_units(h, buf, buf_size);
     if (buf_index < 0)
         return -1;
 
+    /* process last slice */
+    s->avctx->slice.flag_last = 1;
+    s->avctx->slice.end_index = s->mb_x + s->mb_y * s->mb_width;
+    if (s->avctx->slice.skip && !s->avctx->slice.conceal)
+        // previous slice has been skipped, mark it done so that error resilience does not kick in
+        ff_er_add_slice(s,
+                        s->avctx->slice.start_index % s->mb_width,
+                        s->avctx->slice.start_index / s->mb_width,
+                        s->avctx->slice.end_index % s->mb_width - 1,
+                        s->avctx->slice.end_index / s->mb_width,
+                        ER_MB_END & 0x7F);
+    if (avctx->process_slice) {
+        emms_c();
+        avctx->process_slice(s->avctx);
+    }
+    avctx->metrics.type = PSEUDO_SLICE_FRAME_END;
+
     if (!s->current_picture_ptr && h->nal_unit_type == NAL_END_SEQUENCE) {
         av_assert0(buf_index <= buf_size);
         goto out;
@@ -4600,6 +4786,13 @@ not_extra:
         }
     }
 
+    /* frame end processing */
+    avctx->frame.display = *data_size ? pict : NULL;
+    if (avctx->process_slice) {
+        emms_c();
+        avctx->process_slice(avctx);
+    }
+
     assert(pict->data[0] || !*data_size);
     ff_print_debug_info(s, pict);
     // printf("out %d\n", (int)pict->data[0]);
diff --git a/libavcodec/h264_loopfilter.c b/libavcodec/h264_loopfilter.c
index 6395607..7ad5dd7 100644
--- a/libavcodec/h264_loopfilter.c
+++ b/libavcodec/h264_loopfilter.c
@@ -110,6 +110,7 @@ static av_always_inline void filter_mb_edgev(uint8_t *pix, int stride,
     const int alpha = alpha_table[index_a];
     const int beta  = beta_table[qp + b];
     if (alpha ==0 || beta == 0) return;
+    FFMPEG_METRICS_EXTRACT(h->s.avctx->metrics.deblock_edges += 4);
 
     if( bS[0] < 4 || !intra ) {
         int8_t tc[4];
@@ -132,6 +133,7 @@ static av_always_inline void filter_mb_edgecv(uint8_t *pix, int stride,
     const int alpha = alpha_table[index_a];
     const int beta  = beta_table[qp + b];
     if (alpha ==0 || beta == 0) return;
+    FFMPEG_METRICS_EXTRACT(h->s.avctx->metrics.deblock_edges += 2);
 
     if( bS[0] < 4 || !intra ) {
         int8_t tc[4];
@@ -155,6 +157,7 @@ static av_always_inline void filter_mb_mbaff_edgev(H264Context *h, uint8_t *pix,
     const int alpha = alpha_table[index_a];
     const int beta  = beta_table[qp + b];
     if (alpha ==0 || beta == 0) return;
+    FFMPEG_METRICS_EXTRACT(h->s.avctx->metrics.deblock_edges += 2);
 
     if( bS[0] < 4 || !intra ) {
         int8_t tc[4];
@@ -178,6 +181,7 @@ static av_always_inline void filter_mb_mbaff_edgecv(H264Context *h,
     const int alpha = alpha_table[index_a];
     const int beta  = beta_table[qp + b];
     if (alpha ==0 || beta == 0) return;
+    FFMPEG_METRICS_EXTRACT(h->s.avctx->metrics.deblock_edges++);
 
     if( bS[0] < 4 || !intra ) {
         int8_t tc[4];
@@ -200,6 +204,7 @@ static av_always_inline void filter_mb_edgeh(uint8_t *pix, int stride,
     const int alpha = alpha_table[index_a];
     const int beta  = beta_table[qp + b];
     if (alpha ==0 || beta == 0) return;
+    FFMPEG_METRICS_EXTRACT(h->s.avctx->metrics.deblock_edges += 4);
 
     if( bS[0] < 4 || !intra ) {
         int8_t tc[4];
@@ -222,6 +227,7 @@ static av_always_inline void filter_mb_edgech(uint8_t *pix, int stride,
     const int alpha = alpha_table[index_a];
     const int beta  = beta_table[qp + b];
     if (alpha ==0 || beta == 0) return;
+    FFMPEG_METRICS_EXTRACT(h->s.avctx->metrics.deblock_edges += 2);
 
     if( bS[0] < 4 || !intra ) {
         int8_t tc[4];
